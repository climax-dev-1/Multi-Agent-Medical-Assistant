[{"id": "96b89ace-37d7-42ed-77fd-347700000000", "content": "--- Page 1 ---\nDeep Learning Based Brain Tumor Segmentation: A Survey\nZhihua Liua, Lei Tonga, Zheheng Jiangb, Long Chena, Feixiang Zhoua, Qianni Zhangc, Xiangrong Zhangd,\nYaochu Jine, Huiyu Zhoua,\u0003\naSchool of Computing and Mathematical Sciences, University of Leicester, United Kingdom\nbSchool of Computing and Communications, University of Lancaster, United Kingdom\ncSchool of Electronic Engineering and Computer Science, Queen Mary, University of London, United Kingdom\ndSchool of Arti\fcial Intelligence, Xidian University, China\neFaculty of Technology, Bielefeld University, Germany\nAbstract\nBrain tumor segmentation is one of the most challenging problems in medical image analysis. The goal of brain tumor\nsegmentation is to generate accurate delineation of brain tumor regions. In recent years, deep learning methods have\nshown promising performance in solving various computer vision problems, such as image classi\fcation, object detection\nand semantic segmentation. A number of deep learning based methods have been applied to brain tumor segmentation\nand achieved promising results. Considering the remarkable breakthroughs made by state-of-the-art technologies, we\nuse this survey to provide a comprehensive study of recently developed deep learning based brain tumor segmentation\ntechniques. More than 100 scienti\fc papers are selected and discussed in this survey, extensively covering technical\naspects such as network architecture design, segmentation under imbalanced conditions, and multi-modality processes. We also provide insightful discussions for future development directions. Keywords: Brain tumor segmentation, deep learning, network design, data imbalance, multi modalities\n1. Introduction\nMedical imaging analysis has been commonly involved\nin basic medical research and clinical treatment, e.g. computer-aided diagnosis [1], medical record data man-\nagement [2], medical robots [3] and image-based applica-\ntions [4]. Medical image analysis provides useful guidance\nfor medical professionals to understand diseases and inves-\ntigate clinical challenges in order to improve health-care\nquality. Among various tasks in medical image analysis,\nbrain tumor segmentation has attracted much attention\nin the research community, which has been continuously\nstudied (illustrated in Fig. 1 (a)). In spite of tireless ef-\nforts of researchers, as a key challenge, accurate brain tu-\nmor segmentation still remains to be solved, due to various\nchallenges such as location uncertainty, morphological un-\ncertainty, low contrast imaging, annotation bias and data\nimbalance. With the promising performance made by pow-\nerful deep learning methods, a number of deep learning\nbased methods have been applied upon brain tumor seg-\nmentation to extract feature representations automatically\nand achieve accurate and stable performance as illustrated\nin Fig. 1 (b). Glioma is one of the most primary brain tumors that\nstems from glial cells. World Health Organization (WHO)\nreports that glioma can be graded into four di\u000berent lev-\nels based on microscopic images and tumor behaviors [5]. \u0003Corresponding author\nEmail address: hz143@leicester.ac.uk (Huiyu Zhou)Grade I and II are Low-Grade-Gliomas (LGGs) which are\nclose to benign with slow-growing pace. Grade III and IV\nare High-Grade-Gliomas (HGGs) which are cancerous and\naggressive. Magnetic Resonance Imaging (MRI) is one of\nthe most common imaging methods used before and after\nsurgery, aiming at providing fundamental information for\nthe treatment plan. Image segmentation plays an active role in gliomas di-\nagnosis and treatment.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 0, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.4771653543307086, "word_count": 508, "chunking_strategy": "hybrid", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000001"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000001", "content": "Magnetic Resonance Imaging (MRI) is one of\nthe most common imaging methods used before and after\nsurgery, aiming at providing fundamental information for\nthe treatment plan. Image segmentation plays an active role in gliomas di-\nagnosis and treatment. For example, an accurate glioma\nsegmentation mask may help surgery planning, postopera-\ntive observations and improve the survival rate [6], [7], [8]. To quantify the outcome of image segmentation, we de\fne\nthe task of brain tumor segmentation as follows: Given\nan image from one or multiple image modality (e.g. mul-\ntiple MRI sequences), the system aims to automatically\nsegment the tumor area from the normal tissues and to\nclassify each voxel or pixel of the input data into a pre-set\nsub-region category. Finally, the system returns the seg-\nmentation map of the corresponding input. Fig. 2 shows\none exemplar HGG case with di\u000berent MRI sequences as\ninput and corresponding ground truth segmentation map. 1.1. Di\u000berence from Previous Surveys\nA number of notable brain tumor segmentation surveys\nhave been published in the last few years. We present re-\ncent relevant surveys with details and highlights in Table 1. Among them, the closest survey paper to ours is presented\nby Gha\u000bari et al.[9]. The authors in [9] covered a majority\nof submissions from BraTS2012 to BraTS2018 challenges,\nPreprint submitted to Journal of L ATEX Templates November 18, 2021arXiv:2007.09479v3  [eess.IV]  17 Nov 2021", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 1, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.35862068965517246, "word_count": 232, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000000", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000002"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000002", "content": "--- Page 2 ---\nFigure 1: Growth of scienti\fc attention on deep learning based brain tumor segmentation. (a) Keyword frequency map in MICCAI from 2018\nto 2020. The size of the keyword is proportional to the frequency of the word. We observe that 'brain', 'tumor', 'segmentation', and 'deep\nlearning' have drawn large research interests in the community. (b) Blue line represents the number of deep learning based solutions in The\nMultimodal Brain Tumor Segmentation Challenge (BraTS) in each year. Red line represents the Top-1 whole tumor dice score of the test set\nin each year. Researchers shift their interests to deep learning based segmentation methods due to the powerful feature learning ability and\nsystematic performance due to deep learning techniques since 2012 (green dashed line). Best viewed in colors. Figure 2: Exemplar input dataset with di\u000berent MRI modalities and\ncorresponding ground truth segmentation map. Each frame repre-\nsents a unique MRI modality. The last frame on the right is the\nground truth with corresponding manual segmentation annotation. Di\u000berent colors represent di\u000berent tumor sub-regions, i.e., gadolin-\nium (GD) enhancing tumor (green), pertumoral edema (yellow) and\nnecrotic and non-enhancing tumor core (NCR/ECT) (red). Best\nviewed in colors. lacking, however, an analyses based on methodology cat-\negory and highlights. Two recent surveys by Kapoor et\nal. [10] and Hameurlaine et al. [11] also focused on the\nsummarisation of classic brain tumor segmentation meth-\nods. However, both of them lacked the technical anal-\nysis and discussion of deep learning based segmentation\nmethods. A survey of early state-of-the-art brain tumor\nsegmentation methods before 2013 was presented in [12],\nwhere most of the proposals before 2013 combined conven-\ntional machine learning models with hand-crafted features. Liu et al. [13] reported a survey on MRI based brain tumor\nsegmentation in 2014. This survey does not include deep\nlearning based methods as well. Nalepa et al. [14] anal-\nysed the technical details and impacts of di\u000berent kinds ofdata augmentation methods with the application to brain\ntumor segmentation, while ours focuses on the technical\nanalysis of deep learning based brain tumor segmentation\nmethods. There is a number of representative survey papers pub-\nlished with similar topics in recent years. Litjens et al. [4] summarised recent medical image analysis applications\nwith deep learning techniques. This survey gives an over of\nbroad studies on medical image analysis including several\nstate-of-the-art deep learning based brain tumor segmen-\ntation methods before 2017. Bernal et al. [21] reported\na review focusing on the use of deep convolutional neu-\nral networks for brain image analysis. This review only\nhighlights the application of deep convolutional neural net-\nworks. Other important learning strategies such as seg-\nmentation under imbalance condition and learning from\nmulti-modality were not mentioned. Akkus et al. [16]\npresented a survey on deep learning for brain MRI seg-\nmentation. Recently, Esteva et al. [22] presented a survey\non deep learning for health-care applications. This survey\nsummarized how deep learning in computer vision, natu-\nral language processing, reinforcement learning and gen-\neralized methods promote health-care applications.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 2, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.20928853754940713, "word_count": 506, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000001", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000003"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000003", "content": "[22] presented a survey\non deep learning for health-care applications. This survey\nsummarized how deep learning in computer vision, natu-\nral language processing, reinforcement learning and gen-\neralized methods promote health-care applications. For a\nbroader view of object detection and semantic segmenta-\ntion, a survey was recently published in [18], providing the\nimplications on object detection and semantic segmenta-\ntion. Narrowly speaking, the word \"deep learning\" means us-\ning neural network models with stacked functional layers\n(usually the layer number >5) [23]. Neural networks are\nable to learn high dimensional hierarchical features and ap-\nproximate any continuous functions [24], [25]. Considering\nthe achievements and recent advances of deep neural net-\nworks, several surveys have reported the developed deep\nlearning techniques, such as [20] and [19]. 2", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 3, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.1, "word_count": 126, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000002", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000004"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000004", "content": "--- Page 3 ---\nTable 1: A summary of the existing surveys relates to the topic 'brain tumor segmentation'.\nSurvey Title Venue Year Remarks\nAutomated brain tumor segmenta-\ntion using multimodal brain scans:\na survey based on models submitted\nto the BraTS 2012{2018 challenges\n[9]IEEE Reviews in Biomedical Engi-\nneering2019 A review of challenge submissions of\nBraTS during 2012-2018.\nA survey on brain tumor detection\nusing image processing techniques\n[10]2017 7th International Conference\non Cloud computing, Data science\n& Engineering-con\ruence2017 A review of general brain tumor seg-\nmentation methods.\nSurvey of brain tumor segmentation\ntechniques on magnetic resonance\nimaging [11]Nano Biomedicine and Engineering 2019 A general summary of classic brain\ntumor segmentation methods.\nState of the art survey on MRI brain\ntumor segmentation [12]Magnetic Resonance Imaging 2013 Review on convolutional neural net-\nworks used for brain MRI image\nanalysis.\nA survey of MRI-based brain tumor\nsegmentation methods [13]Tsinghua Science and Technology 2014 Review on MRI based brain tumor\nsegmentation methods.\nData augmentation for brain-tumor\nsegmentation: a review [14]Frontiers in Computational Neuro-\nscience2019 Analysed the technical details and\nimpacts of di\u000berent kinds of data\naugmentation methods with the ap-\nplication to brain tumor segmenta-\ntion.\nA survey on deep learning in medical\nimage analysis [4]Medical Image Analysis 2017 A comprehensive review on deep\nlearning based medical image analy-\nsis.\nDeep convolutional neural networks\nfor brain image analysis on magnetic\nresonance imaging: a review [15]Arti\fcial Intelligence in Medicine 2018 A review on use of deep convolu-\ntional neural networks for brain im-\nage analysis.\nDeep learning for brain MRI seg-\nmentation: state of the art and fu-\nture directions [16]Journal of Digital Imaging 2017 A survey on deep learning for brain\nMRI segmentation.\nA guide to deep learning in health-\ncare [17]Nature Medicine 2019 A survey on deep learning for\nhealth-care.\nDeep learning for generic object de-\ntection: A survey [18]International Journal of Computer\nVision2020 A comprehensive review on deep\nlearning based object detection.\nDeep learning [19] Nature 2015 An introduction review on deep\nlearning and its application.\nRecent advances in convolutional\nneural networks [20]Pattern Recognition 2018 A survey on convolutional neural\nnetworksand its application on com-\nputer vision, language processing\nand speech.\nDeep Learning Based Brain Tumor\nSegmentation: A SurveyOurs - A comprehensive survey of deep\nlearning based brain tumor segmen-\ntation.\n3", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 4, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "paragraph", "importance_score": 0.22792207792207791, "word_count": 385, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000003", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000005"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000005", "content": "--- Page 4 ---\nFigure 3: Challenges in segmentation of brain glioma tumors. (a)\nshows glioma tumor exemplars with various sizes and locations in-\nside the brain. (b) and (c) show the statistical information of the\ntraining set in the multimodal brain tumor segmentation challenge\n2017 (BraTS2017). The left hand side of (b) shows the FLAIR and\nT2 intensity projection, and the right hand side shows the T1ce and\nT1 intensity projection. (c) is the pie chart of the training data with\nlabels, where the top \fgure shows the HGG labels while the bottom\n\fgure shows the LGG labels. We here experience region and label\nimbalance problems. Best viewed in colors.1.2. Scope of This Survey\nIn this survey, we have collected and summarized the\nresearch studies reported on over one hundred scienti\fc\npapers. We have examined major journals in the scien-\nti\fc community such as Medical Image Analysis and IEEE\nTransactions on Medical Imaging. We also evaluated pro-\nceedings of major conferences, such as ISBI, MICCAI,\nIPMI, MIDL, CVPR, ECCV and ICCV, to retain fron-\ntier medical imaging research outcomes. We reviewed an-\nnual challenges and their related competition entries such\nas The Multimodal Brain Tumor Segmentation Challenge\n(BraTS). In addition, the pre-printed versions of the es-\ntablished methods on arXiv are also included as a source\nof information.\nThe goal of this survey is to present a comprehensive\ntechnical review of deep learning based brain tumor seg-\nmentation methods, according to architectural categories\nand strategy comparisons. We wish to explore how di\u000ber-\nent architectures a\u000bect the segmentation performance of\ndeep neural networks and how di\u000berent learning strategies\ncan be further improved for various challenges in brain tu-\nmor segmentation. We cover diverse high level perspec-\ntives, including e\u000bective architecture design, imbalance\nsegmentation and multi-modality process. The taxonomy\nof this survey is made (Fig. 5) such that our categorization\ncan help the reader to understand the technical similari-\nties and di\u000berences between segmentation methods. The\nproposed taxonomy may also enable the reader to identify\nopen challenges and future research directions.\nWe \frst present the background information of deep\nlearning based brain tumor segmentation methods in Sec-\ntion 2 and the rest of this survey is organised as follows:\nIn Section 3, we review the design paradigm of e\u000bective\nsegmentation modules and network architectures. In Sec-\ntion 4, we categorise, explore and compare the solutions for\ntackling the data imbalance issue, which is a long-standing\nproblem in brain tumor segmentation. As multi-modality\nprovides promising solutions towards accurate brain tu-\nmor segmentation, we \fnally review the methods of utilis-\ning multi-modality information in Section 5. We conclude\nthis paper in Section 6. We also build up a regularly main-\ntained project page to accommodate the updates related\nto this survey.1\n2. Background\n2.1. Research Challenges\nDespite signi\fcant progress that has been made in brain\ntumor segmentation, state-of-the-art deep learning meth-\nods still experience di\u000eculties with several challenges to\nbe solved. The challenges associated with brain tumor\nsegmentation can be categorised as follows:\n1http://github.com/ZhihuaLiuEd/SoTA-Brain-Tumor-\nSegmentation.\n4", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 5, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "paragraph", "importance_score": 0.20859375000000002, "word_count": 512, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000004", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000006"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000006", "content": "--- Page 5 ---\nFigure 4: The evolution of brain tumor segmentation with selective milestones over the past decade. Best viewed in colors. 1.Location Uncertainty Glioma is mutated from\ngluey cells which surround nerve cells. Due to the\nwide spatial distribution of gluey cells, either High-\nGrade Glioma (HGG) or Low-Grade Glioma (LGG)\nmay appear at any location inside the brain. 2.Morphological Uncertainty Di\u000berent from a rigid\nobject, the morphology, e.g. shape and size, of di\u000ber-\nent brain tumors varies with large uncertainty. As the\nexternal layer of a brain tumor, edema tissues show\ndi\u000berent \ruid structures, which barely provide any\nprior information for describing the tumor's shapes. The sub-regions of a tumor may also vary in shape\nand size. 3.Low Contrast High resolution and high contrast im-\nages are expected to contain diverse image informa-\ntion [26]. Due to the image projection and tomogra-\nphy process, MRI images may be of low quality and\nlow contrast. The boundary between biological tis-\nsues tends to be blurred and hard to detect. Cells\nnear the boundary are hard to be classi\fed, which\nmakes precise segmentation more di\u000ecult and harder\nto achieve. 4.Annotation Bias Manual annotation highly de-\npends on individual experience, which can introduce\nan annotation bias during data labeling. As shown\nin Fig. 3 (a), it seems that some annotations tend to\nconnect all the small regions together while the other\nannotations can label individual voxels precisely. The\nannotation biases have a huge impact on the segmen-\ntation algorithm during the learning process [27]. 5.Imbalanced Issue As shown in Fig. 3 (b) and (c),\nthere exists an imbalanced number of voxels in di\u000ber-\nent tumor regions. For example, the necrotic/non-\nenhancing tumor core (NCR/ECT) region is much\nsmaller than the other two regions. The imbalanced\nissue a\u000bects the data-driven learning algorithm as the\nextracted features may be highly in\ruenced by large\ntumor regions [28].2.2. Progress in the Past Decades\nRepresentative research milestones of brain tumor seg-\nmentation are shown in Fig. 4. In the late 90s', researchers\nZhu et al. [29] started to use a Hop\feld Neural Network\nwith active contours to extract the tumor boundary and di-\nlate the tumor region. However, training a neural network\nwas highly constrained due to the computational resource\nlimitation and technical supporting. From late 90s' to\nearly 20s', most of the brain tumor segmentation methods\nfocused on traditional machine learning algorithms with\nhand-crafted features, such as expert systems with multi-\nspectral histogram [30], segmentation with templates [31],\n[32], graphical models with intensity histograms [33], [34],\ntumor boundary detection from latent atlas [35]. These\nearly works pioneered the use of machine learning in solv-\ning brain tumor segmentation problems. However, early\nresearch works have signi\fcant shortcomings. First, most\nof the early works only focused on the segmentation of\nthe whole tumor region, that is, the segmentation result\nhas only one category. Compared with recent brain tumor\nsegmentation algorithms, early works are formulated with\nstrong conditions, relying on unrealistic assumptions.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 6, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.1595238095238095, "word_count": 504, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000005", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000007"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000007", "content": "First, most\nof the early works only focused on the segmentation of\nthe whole tumor region, that is, the segmentation result\nhas only one category. Compared with recent brain tumor\nsegmentation algorithms, early works are formulated with\nstrong conditions, relying on unrealistic assumptions. Sec-\nond, manually designed feature engineering is constrained\nby prior knowledge, which cannot be fully generalised. Last but not least, early research works fail to address\nsome challenges such as appearance uncertainty and data\nimbalance. With the revolutionary breakthrough by deep learning\ntechnology [36], researchers began to focus on using deep\nneural networks to solve various practical problems. Pi-\noneering works from Zikic et al. [37], Havaei et al. [38],\nPereira et al. [39] intend to design customized deep con-\nvolutional neural networks to achieve accurate brain tu-\nmor segmentation. With breakthrough brought by Fully\nConvolutional Network (FCN) [40] and U-Net [41], recent\ninnovations [42], [43] on brain tumor segmentation focus\non building encoder-decoder networks without fully con-\n5", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 7, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.2851851851851852, "word_count": 162, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000006", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000008"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000008", "content": "--- Page 6 ---\nFigure 5: Our proposed taxonomy of deep learning based brain tumor segmentation methods. Best viewed in colors.\nnected layers to achieve end-to-end tumor segmentation.\nA long-standing challenge in brain tumor segmentation\nis data imbalance. To e\u000bectively deal with the imbal-\nance problem, researchers try di\u000berent solutions, such as\nnetwork cascade and ensemble [44], [45], [46], multi-task\nlearning [47], [48], and customized loss functions [49]. An-\nother solution is to fully utilise information from multi-\nmodality. Recent research focused on modality fusion [50]\nand dealing with modality missing [51].\nBased on the evolution, we generally categorise the ex-\nisting deep learning based brain tumor segmentation meth-\nods into three categories, i.e., methods with e\u000bective archi-\ntectures, methods for dealing with imbalanced condition\nand methods of utilising multi-modality information. Fig.\n5 shows a taxonomy of the research work in deep learning\nbased brain tumor segmentation.\n2.3. Related Problems\nThere are a number of unsolved problems that relates\nto brain tumor segmentation. Brain tissue segmentation\noranatomical brain segmentation aims to label each unit\nwith a unique brain tissue class. Their task assumes that\nthe brain image does not contain any tumor tissue or\nother anomalies [52], [53]. The goal of white matter le-\nsion segmentation is to segment the white matter lesion\nfrom the normal tissue. In their task, the white matter\nlesion does not contain sub-regions such as tumor cores,\nwhere segmentation may be achieved through binary clas-\nsi\fcation methods. Tumor detection aims to detect ab-normal tumors or lesion and reports the predicted class\nof each tissue. Generally, this task has the bounding box\nas the detection result and the label as the classi\fcation\nresult [54], [55],[56]. It is worth mentioning that some re-\nsearch methods in brain tumor segmentation only return\nthe single label segmentation mask or the center point of\nthe tumor core without sub-region segmentation. In our\npaper, we focus on tumor segmentation with sub-region\nlevel semantic segmentation as the main topic. Disorder\nclassi\fcation is to extract pre-de\fned features from brain\nscan images and then classify feature representations into\ngraded disorders such as High-Grade-Gliomas (HGGs) vs\nLow-Grade-Gliomas (LGGs), Mild Cognitive Impairment\n(MCI) [57], Alzheimer's Disease (AD) [58] and Schizophre-\nnia [59]. Survival Prediction identi\fes tumors' patterns\nand activities [60] in order to predict the survival rate as\na supplementary to clinical diagnosis [61]. Both disorder\nclassi\fcation and survival prediction can be regarded as\ndown-stream tasks, based on the tumor segmentation out-\ncomes.\n2.4. Contributions of this survey\nA large number of deep learning based brain tumor seg-\nmentation methods have been published with promising\nresults. Our paper, as a platform, provides a comprehen-\nsive and critical survey of state-of-the-art brain tumor seg-\nmentation methods. We anticipate that this survey sup-\nplies useful guidelines and coherent technical insights to\nacademia and industry. The major contributions of this\n6", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 8, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "paragraph", "importance_score": 0.2623700623700624, "word_count": 481, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000007", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000009"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000009", "content": "--- Page 7 ---\nsurvey can be summarised as follows:\n1. To our best knowledge, this is the \frst survey to cater-\ngorise and outline deep learning based brain tumor\nsegmentation methods with a structured taxonomy of\nvarious important technical perspectives. 2. We present the reader with a summarisation of tech-\nnological progress of deep learning base brain tumor\nsegmentation with detailed background information\nand system comparisons (e.g. Tables 1, 5). 3. We carefully and extensively compares existing meth-\nods based on results from public accessible challenges\nand datasets (e.g. Tables 2, 3, 4. ), with critical sum-\nmaries and insightful discussions. 3. Designing E\u000bective Segmentation Networks\nCompared with complex feature engineering pipelines to\nextract useful features, recent deep learning mainly relies\non designing e\u000bective deep neural networks to automati-\ncally extract high-dimensional discriminative features. De-\nsigning e\u000bective modules and network architectures has\nbecome one of the important factors for achieving accu-\nrate segmentation performance. In this section, we re-\nviewed two important design guidelines for deep learning\nbased brain tumor segmentation: to design e\u000bective mod-\nules and network architecture. There are mainly two principles to follow when designing\ne\u000bective components. One is to learn high level semantics\nand localise precious targets, through the enlargement of\nthe receptive \feld [62], [63], [64], attention mechanism [65],\n[66], [48] feature fusion update [67], [68] and other forms. The other way is to reduce the amount of the network\nparameters and speed up during training and inference,\nthereby saving computational time and resources[69], [70],\n[71], [72], [73], [74], [75]. The design of the network architecture is mainly re-\n\rected in the transition from a single-channel network to\na multi-channel network, from a network with fully con-\nnected layers to a fully convolutional network, from a sim-\nple network to a deep cascaded network. The purpose is to\ndeepen the network, enhance the feature learning ability of\nthe network and completes more precise segmentation. In\nthe following, we divide theses methods and review them\ncomprehensively. A systematical comparison between var-\nious network architectures and modules is shown in Fig. 6. 3.1. Designing Specialised Modules\n3.1.1. Modules for Higher Accuracy\nNumerous methods for brain tumor segmentation fo-\ncuses on designing e\u000bective modules inside neural net-\nworks, aiming to stabilise training, learning informative,\ndiscriminative, and conducive features for accurate seg-\nmentation. Early design work followed the pattern of well-\nknown networks such as AlexNet [36] and gradually deep-\nened the network depth by stacking convolutional blocks.Early research works such as [81], [82] and [43] stacked sev-\neral blocks with convolutional layers composed of a large\nkernel size (typically greater than 5), pooling layers and\nactivation layers together. Blocks with a large size con-\nvolution kernel enable us to capture useful details with a\nlarge number of parameters to be trained. Other research\nworks such as [37] and [39] followed the pattern of VGG\n[83] to build convolutional layers with a small sized kernel\n(typically 3) as basic blocks.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 9, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.2602409638554217, "word_count": 498, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000008", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000010"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000010", "content": "Blocks with a large size con-\nvolution kernel enable us to capture useful details with a\nlarge number of parameters to be trained. Other research\nworks such as [37] and [39] followed the pattern of VGG\n[83] to build convolutional layers with a small sized kernel\n(typically 3) as basic blocks. Further research works such\nas [38] stacked hybrid blocks with a combination of dif-\nferent kernel sizes, where large sized kernels tend to \fnd\nglobal features (such as tumor location and size) with a\nlarge receptive \feld and small kernels tend to contain lo-\ncal features (such as boundary and texture) with a small\nreceptive \feld. As stacking two 3 \u00023 convolutional layers\nleads to equal sized reception \felds while maintaining less\nparameters, compared with a single 5 \u00025 layer, most re-\ncent tumor segmentation works constructed basic network\nblocks, based on stacking 3 \u00023 layers, and started to ex-\ntend to volumetric reconstruction in MRI with 3 \u00023\u00023\nkernels [84], [85]. As the number of stacked layers increases, the network\nis getting deeper, causing the issue of gradient explosion\nand vanishing during the training process. In order to sta-\nbilise system training and reach higher segmentation ac-\ncuracy, early brain tumor segmentation methods such as\n[86] and [76] followed ResNet[87] and introduced residual\nconnection into module design. Residual connection helps\nsolving the problem of gradient vanishing and explosion,\nby adding the input of a convolution module to its output,\nwhich avoids degradation and converges faster with better\naccuracy. Now, residual connection has become one of the\nstandard operations for designing modules and complex\nnetwork architectures. In the following works [88], [78],\n[89] and [90], the authors followed Densenet [91] and ex-\npanded residual connection to dense connection. Although\ndense connection design looks more conducive to gradient\nback-propagation, the complex close connection structure\ncan cause multiple usage of the computing memory during\nthe network training. By stacking convolution modules and using residual con-\nnections inside and outside modules, neural networks can\nbe deeper and features can be learnt with higher dimen-\nsions and uncertainty. However, this process may lead to\nthe sacri\fce of spatial resolution, whereas the resolution of\nhigh dimensional feature maps is much smaller than that\nof the original data. In order to preserve the spatial res-\nolution of data whilst still expanding the receptive \feld,\n[62], [63], [64] replaced the standard convolution layer with\na dilated convolution layer [92]. The dilated convolution\ncomes up with several bene\fts. First, dilation convolution\nenlarges the receptive \feld without introducing additional\nparameters. Larger receptive \felds are helpful for seg-\nmenting large-area targets, such as edema. Second, dilated\nconvolution avoids the loss of spatial resolution. Thus, the\nposition of the object to be segmented can be accurately\nlocalised in the original input space. However, the problem\n7", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 10, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.06410256410256411, "word_count": 468, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000009", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000011"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000011", "content": "--- Page 8 ---\nFigure 6: Structural comparison between representative methods based on designing e\u000bective network modules and architectures. From\ntop-left to bottom-right: (a1) CNN in [37], (b1) CNN with (b2) residual convolution module [76], (c1) CNN with (c2) full resolution residual\nunit [77], (d1) CNN with (d2) dense connection module [78], (e1) CNN with (e2) residual dilation block [63], (f1) CNN with (f2) atrous\nconvolution feature pyramid module [79], (g1) FCN with (g2) multi-\fber unit [71], (h1) FCN with (h2) reversible block [70] and (i1) FCN\nwith (i2) modality fusion module [80]. Best viewed in colors.\n8", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 11, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "paragraph", "importance_score": 0.0, "word_count": 100, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000010", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000012"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000012", "content": "--- Page 9 ---\nof incorrect localisation and segmentation of small struc-\ntures remains to be solved. In response to this problem,\n[93] proposed to design a multi-scale dilation convolution\nor atrous spatial pyramid pooling module, capturing the\nsemantic context that describes subtle details of the ob-\nject. 3.1.2. Modules for E\u000ecient Computation\nDesigning and stacking complex modules may help e\u000bec-\ntively learn high-dimensional discriminative features and\nachieve precise segmentation, but it requires high compu-\ntational resources and long training and inference time. In response to this request, many works have adopted\nlightweight ideas in module design. With similar accuracy,\nfewer computing resources are required by lightweight ar-\nchitectures, training and reasoning time is shorter, and the\nspeed is faster. [94] is one of the earliest research works\naiming at speeding up brain tumor segmentation. The\nauthors of [94] reordered the input data (a data sample\nrotated by 6-degrees) so that the samples with high visual\nsimilarity are placed closer in the memory, in an attempt\nto speed up I/O communication. Instead of managing the\ninput data, [72] chose to build a U-Net variant with de-\ncreased down-sampling channels to reduce the computa-\ntional cost. The above-mentioned works used less computational re-\nsources, but lose learning information and decreased seg-\nmentation accuracy. Inspired by reversible residual net-\nwork [95], [70] introduced reversible blocks into U-Net\nwhere each layer's activation can be collected from the\nprevious layer's output during the backward pass process. Thus, no additional memory is used to store intermedi-\nate activation and hence reduce memory cost. [73] fur-\nther extend reversible blocks by introducing Mobile Re-\nversible Convolution Blocks (MBConvBlock) used in Mo-\nbileNetV2 [96] and E\u000ecientNet [97]. In addition to the re-\nversible computation design, MBConvBlock replaced stan-\ndard convolutions with depthwise separable convolutions. Depthwise separable convolutions \frst split the computa-\ntion of feature maps accordingly using depthwise convolu-\ntion and merge the feature maps together using 1 \u00021\u00021\npointwise convolutions, which further reduced parameters\ncompared with the standard convolution. Later research\nworks, including 3DESPNet[98] and DMFNet [71], further\nextend this idea with dilated convolutions, requiring less\ncomputational resources while preserving most spatial res-\nolutions. 3.2. Designing E\u000bective Architectures\nA major factor that promotes prosperity and develop-\nment of deep neural networks in various \felds is to invest\ne\u000borts in designing intelligent and e\u000bective network archi-\ntectures. We divide most deep learning based brain tumor\nsegmentation networks into single/multiple path networks\nand encoder-decoder networks according to the character-\nistics of network structures. Single and multiple path net-\nworks are used to extract features and classify the center\nFigure 7: A high level comparison between single-path and two-path\nCNN. Best viewed in colors. pixels of the input patch. Encoder-Decoder networks are\ndesigned in an end-to-end fashion, that is, the encoder\nenables deep feature to be extracted from part of or the\nentire image, and then the decoder conducts feature-to-\nsegmentation mapping. In the following subsections, we\nconduct a systematic analysis and comparison of variant\narchitecture designs. 3.2.1.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 12, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.059642147117296214, "word_count": 503, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000011", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000013"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000013", "content": "In the following subsections, we\nconduct a systematic analysis and comparison of variant\narchitecture designs. 3.2.1. Multi-Path Architecture\nHere we refer network path as the \row of data processing\n(Fig. 7). Many research works e.g. [39], [99], [37] use single\npath networks due to their computational e\u000eciency. Com-\npared with single path networks, multi-path networks can\nextract di\u000berent features from di\u000berent pathways of di\u000ber-\nent scales. The extracted features are combined (added or\nconcatenated) together for further processing. A common\n9", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 13, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.0, "word_count": 84, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000012", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000014"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000014", "content": "--- Page 10 ---\ninterpretation is that a large scale path (path with a large\nsize's kernel or input etc.) allows us to learn global fea-\ntures. Small scale's paths (paths with a small size's kernel\nor input etc.) allows us to learn features known as local\nfeatures. Similar to the functionality mentioned in the pre-\nvious section, global features tend to provide global infor-\nmation such as tumor location, size and shape while local\nfeatures provide descriptive details such as tumor texture\nand boundary. The work of Havaei et al. [38] is one of the early multi-\npath network based solutions. The author reported a novel\ntwo pathway structure that learns local tumor informa-\ntion as well as global contexts. The local pathway uses\na 7\u00027 convolution kernel and the global pathway uses a\n13\u000213 convolution kernel. In order to utilise CNN archi-\ntectures, the authors designed several variant architectures\nthat concatenate CNN outputs. Castillo et al. [76] used a\n3 pathway CNN to segment brain tumors. Di\u000berent from\n[38] that used kernels in di\u000berent scales, [76] inputs each\npath with di\u000berent sizes' patches e.g. patches with low\n(15\u000215), medium(17 \u000217) and normal (27 \u000227) resolu-\ntions. Thus, each path can learn speci\fc features under\nthe condition of di\u000berent spatial resolutions. Inspired by\n[38], Akil et al. [100] extended the network structure with\noverlapping patch prediction methods, where the center of\nthe target patch is associated with the neighbouring over-\nlapping patches. Instead of building multi-path networks with di\u000berent\nsizes' kernels, other research works attempt to learn local-\nto-global information from the input directly. For exam-\nple, Kamnitsas et al. [101] presented a dual pathway\nnetwork which considers the input with di\u000berent sizes'\npatches, known as the normal resolution input of size\n25\u000225\u000225 and the low resolution input of size 19 \u000219\u000219. Di\u000berent from [76], the authors in [101] applied small con-\nvolution kernels with a size of 3 \u00023\u00023 on both pathways. Later research works by Zhao et al. [74] also designed a\nmulti-scale CNN with a large scale path with the input\nsize of 48 \u000248, a middle scale path with the input size\nof 18 \u000218 and a small scale path with the input size of\n12\u000212. 3.2.2. Encoder-Decoder Architecture\nThe input of the single and multiple path network for\nbrain tumor segmentation is a patch or a certain area of\nthe image, and the output is the classi\fcation outcome of\nthe patch or the classi\fcation outcome of the central pixel\nof the input. It is very challenging to promote an accurate\nmapping from the patch level to the category label. First\nof all, the segmentation performance of single and multiple\npath network is easily a\u000bected by the size and quality of\nthe input patch. A small sized input patch holds incom-\nplete spatial information, while a large sized patch requires\nmore computational resources. Secondly, the feature-to-\nlabel mapping is mostly conducted by the last fully con-\nnected layer.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 14, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.05952380952380952, "word_count": 504, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000013", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000015"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000015", "content": "A small sized input patch holds incom-\nplete spatial information, while a large sized patch requires\nmore computational resources. Secondly, the feature-to-\nlabel mapping is mostly conducted by the last fully con-\nnected layer. A simple fully connected layer cannot fully\nrepresent the feature space where complicated fully con-nected layers may overload the computer's memory. Last\nbut not least, this feature-to-label mapping is not of an\nend-to-end mode, which signi\fcantly increases the opti-\nmisation cost. To tackle these problems, recent research\nworks start to use fully convolutional network (FCN) [40]\nand U-Net [41] based encoder-decoder networks, establish\nan end-to-end fashion from the input image to the output\nsegmentation map, and further improve the segmentation\nperformance of networks. Jesson et al. [85] extended standard FCN by using a\nmulti-scale loss function. One limitation of FCN is that\nFCN does not explicitly model the contexts in the label\ndomain. In [85], the FCN variant minimised the multi-\nscale loss by combining higher and lower resolution fea-\nture maps to model the contexts in both image and label\ndomains. In [102], researchers proposed a boundary aware\nfully convolutional neural network, including two branches\nfor up-sampling. The boundary detection branch aims to\nlearn and model boundary information of the whole tumor\nas a binary classi\fcation problem. The region detection\nbranch learns to detect and classify sub-region classes of\nthe tumor. The outputs from the two branches are con-\ncatenated and fed to a block of two convolutional layers\nwith a softmax classi\fcation layer. One important mutant of FCN is U-Net [41]. U-Net\nconsists of a contracting path to capture features and a\nsymmetric expanding path that enables precise localisa-\ntion. One advantage of using U-Net, compared against\ntraditional FCN, is the skip connections between the con-\ntracting and the expanding paths. The skip connections\npass feature maps from the contracting path to the ex-\npanding path and concatenate the feature maps from the\ntwo paths directly. The original image data through skip\nconnections can help the layers in the contracting path re-\ncover details. Several research works have been proposed\nfor brain tumor segmentation based on U-Net. For exam-\nple, Brosch et al. [103] used a fully convolutional network\nwith skip connections to segment multiple sclerosis lesions. Isensee et al. [104] reported a modi\fed U-Net for brain\ntumor segmentation, where the authors used a dice loss\nfunction and extensive data augmentation to successfully\navoid over-\ftting. In [105], the authors used zero padding\nto keep the identical output dimension for all the con-\nvolutional layers in both down-sampling and up-sampling\npaths. Chang et al. [86] reported a fully convolutional\nneural network with residual connections. Similar to skip\nconnection, the residual connection allows both low- and\nhigh-level feature maps to contribute towards the \fnal seg-\nmentation. In order to extract information from the original volu-\nmetric data, Milletari et al. [106] introduced a modi\fed\n3D version of U-Net, called V-Net, with a customized dice\ncoe\u000ecient loss function. Beers et al.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 15, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.11, "word_count": 500, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000014", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000016"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000016", "content": "[106] introduced a modi\fed\n3D version of U-Net, called V-Net, with a customized dice\ncoe\u000ecient loss function. Beers et al. [107] introduced 3D\nU-Nets based on sequential tasks, which uses the entire\ntumor ground truth as an auxiliary channel to detect en-\nhancing tumors and tumor cores. In the post-processing\nstage, the authors employed two additional U-Nets that\n10", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 16, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.0, "word_count": 60, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000015", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000017"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000017", "content": "--- Page 11 ---\nFigure 8: A high level comparison between di\u000berent fully convolutional networks (FCNs). Best viewed in colors. serve to enhance prediction for better classi\fcation out-\ncomes. The input patches consist of seven channels: four\nanatomical MR and three label maps corresponding to the\nentire tumor, enhancing tumor, and tumor core. 3.3. Summary\nIn this section, we review and compare the work fo-\ncused on module and network architecture design in brain\ntumor segmentation. Table 2 shows the results generated\nby methods focused on module and network architecture\ndesign in brain tumor segmentation. We drawn key infor-\nmation of these research works and list it below. 1. By designing custom modules, the accuracy and speed\nof the network can be improved. 2. By designing a customised architecture, it can help\nthe network learn features at di\u000berent scales, which is\none of the most important steps to achieve accurate\nbrain tumor segmentation. 3. The design of modules and networks heavily relies on\nhuman experience. In the future, we anticipate the\napplication of network architecture search for search-\ning e\u000bective brain tumor segmentation architectures\n[118], [119], [120], [121]. 4. Most of the existing network architecture designs do\nnot combine domain knowledge about brain tumor,\nsuch as modelling degree information and physically\ninspired morphological information within tumor seg-\nmentation network. 4. Segmentation under Imbalanced Condition\nOne of the long standing challenges for brain tumor seg-\nmentation is the data imbalance issue. As shown in Fig 3(c), imbalance is mainly re\rected in the number of pixels\nin the sub-regions of the brain tumor. In addition, there\nis also an imbalance issue in patient samples, that is, the\nnumber of the HGG cases is much more than that of the\nLGG cases. At the same time, labeling biases introduced\nby manual experts can also be treated as a special form of\ndata imbalance (di\u000berent experts have di\u000berent standards,\nresulting in imbalanced labeling results). Data imbalance\nplays a signi\fcant e\u000bect on learning algorithms especially\ndeep networks. The main manifestation is that learning\nmodels trained with imbalanced data tend to learn more\nabout the dominant groups, e.g. to learn the morphol-\nogy of the edema area, and to learn HGG instead of LGG\npatients) [122], [123], [49]. It is less likely to deal with the data imbalance issue\nby designing a speci\fc module or architecture. Numerous\nworks have presented many improvement strategies to ad-\ndress data imbalance. According to core components of\nthese strategies, we divide the existing methods into three\ncategories: multi-network driven ,multi-task driven\nandcustom loss function driven approaches. 4.1. Multi-Network Driven Approaches\nEven if complex modules and architectures have been\ndesigned to ensure the learning of high-dimensional dis-\ncriminative features, a single network often su\u000bers from\nthe problem of data imbalance. Inspired by the methods\nsuch as multi-expert systems, people have started to con-\nstruct complex network systems to e\u000bectively deal with\ndata imbalance and achieved promising segmentation per-\nformance.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 17, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.21000000000000002, "word_count": 500, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000016", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000018"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000018", "content": "Multi-Network Driven Approaches\nEven if complex modules and architectures have been\ndesigned to ensure the learning of high-dimensional dis-\ncriminative features, a single network often su\u000bers from\nthe problem of data imbalance. Inspired by the methods\nsuch as multi-expert systems, people have started to con-\nstruct complex network systems to e\u000bectively deal with\ndata imbalance and achieved promising segmentation per-\nformance. Common multi-network systems can be divided\ninto network cascade and network ensemble, according to\ndata \rows shared between multiple networks. 11", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 18, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.0, "word_count": 84, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000017", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000019"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000019", "content": "--- Page 12 ---\nTable 2: Comparison between novel methods focuses on e\u000bective network design. We categorise the methods based on their main contributions. In column Input , 'P' means patch\nand 'I' means image. ' Dim ' means the dimension of the network. In column Loss , 'CE' means cross-entropy loss, 'mIoU' means the mean Intersection of Union and 'KL' means\nKL-divergence. In column Dice andHausdor\u000b , 'WT' means whole tumor, 'TC' means tumor core and 'ET' means enhancing tumor. Column Dataset indicates the associated dataset\nwith the segmentation performance. In column Type, 'CV' means cross-validation on the BraTS training set, 'V' means BraTS validation set and 'T' means BraTS test set. '-' means\nthe entry has not been reported in the original paper.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 19, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.0, "word_count": 126, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000018", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000020"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000020", "content": "In column Type, 'CV' means cross-validation on the BraTS training set, 'V' means BraTS validation set and 'T' means BraTS test set. '-' means\nthe entry has not been reported in the original paper. Methods Input Dim LossDice Hausdor\u000b Dataset\nWT TC ET WT TC ET Year Type\nDesigning\nE\u000bective\nModules[81] P 2D - 0.81 0.79 - - - - 2014 V\n[43] I 2D Softmax 0.84 0.73 0.62 - - - 2015 T\n[82] P 2D - - - - - - - - -\n[84] I 3D CE 0.91 0.83 - - - - 2015 CV\n[78] I 2D CE+Soft Dice 0.87 0.68 - - - - 2017 V\n[88] I 3D Dice 0.9 0.82 0.78 5.14 6.64 7.71 2020 V\n[79] I 2D - 0.86 0.77 0.74 - - - 2018 V\n[89] I 2D CE+Dice+MP 0.91 0.85 0.79 4.71 5.7 35.01 2020 V\n[94] P 3D Multinomial Logistic - - - - - - - -\n[72] I 2D Dice+Edge+Mask 0.9 0.82 0.78 5.41 7.26 5.282 2019 V\n[70] I 3D Dice 0.91 0.86 0.81 5.61 7.83 3.35 2018 V\n[73] I 3D - - - - - - - - -\n[98] I 2D mIoU 0.85 0.78 0.67 9.6 8.67 5.5 2018 T\n[71] I 3D Generalized Dice 0.91 0.85 0.8 4.66 6.44 3.06 2018 V\nDesigning\nE\u000bective\nArchitectures[37] P 2D Log Loss 0.84 0.73 0.69 - - - 2013 V\n[39] P 2D Categorical CE 0.78 0.65 0.75 15.83 26.54 6.99 2015 T\n[38] P 2D Surrogate Loss 0.84 0.71 0.57 - - - 2013 T\n[76] P 3D - - - - - - - 2015 CV\n[45] P 3D CE/IoU 0.9 0.8 0.74 4.23 6.56 4.5 2017 V\n[74] P 2D - - - - - - - - -\n[85] I 3D Categorical CE 0.9 0.75 0.71 4.16 8.65 6.98 2017 V\n[104] I 3D Dice 0.9 0.8 0.73 7 9.48 4.55 2017 V\n[105] I 2D Soft Dice 0.86 0.86 0.65 - - - 2015 CV\n[86] I 2D - 0.89 0.83 0.78 8 10 5.9 2016 T\n[108] P 2D KL 0.87 0.74 0.65 - - - 2017 V\n[109] P 3D KL 0.89 0.74 0.73 - - - 2017 V\n[110] I 2D Softmax 0.82 0.63 0.57 - - - 2017 V\n[111] I 3D Dice 0.84 0.78 0.68 9.2 7.71 4.52 2018 T\n[112] I 2D - 0.86 0.73 0.72 7.5 9.5 5.7 2018 V\n[113] I 3D Focal 0.9 0.84 0.77 5.18 6.28 3.51 2018 V\n[42] P 3D Dice 0.91 0.86 0.81 4.27 6.52 2.41 2018 V\n[114] I 3D Dice 0.88 0.79 0.72 29.21 11.06 7.93 2018 V\n[47] I 3D Dice+L2+KL 0.91 0.87 0.82 4.52 6.85 3.92 2018 V\n[115] P 3D CE+Dice 0.91 0.84 0.75 4.57 5.58 3.84 2019 V\n[116] I 3D Jaccard+Focal 0.91 0.85 0.79 4.09 5.88 18.19 2020 V\n[117] I 2D Dice 0.91 0.85 0.8 4.3 5.69 20.56 2020 V\n12", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 20, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.0, "word_count": 495, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000019", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000021"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000021", "content": "--- Page 13 ---\nFigure 9: The structure of cascaded convolutional networks for brain\ntumor segmentation, modi\fed from the original structure reported\nin [46]. WNet, TNet and ENet are used for segmenting the whole\ntumor, tumor core and enhancing tumor core, respectively. 4.1.1. Network Cascade\nThe de\fnition of network cascade is that, in a serially\nconnected network, the output of an upstream network is\npassed to the downstream network as input. This topology\nsimulates the coarse-to-\fne strategy, that is, the upstream\nnetwork extracts rough information or features, and the\ndownstream network subdivides the input and achieves a\n\fne-grained segmentation. The earliest work of adopting the cascade strategy was\nundertaken by Wang et al [46] (Fig. 9). In their work, the\nauthor proposed to connect three networks in series. First,\nWNet segmented Whole Tumor, and output the segmen-\ntation result of Whole Tumor to TNet, and TNet traces\nTumor Core. Finally, the segmentation result of TNet\nis handed over to ENet for the segmentation of Enhanc-\ning Tumor. This design logic is inspired by the attributes\nof the tumor sub-region, where it is assumed that Whole\nTumor, Tumor Core, and Enhancing Tumor are included\none by one. Therefore, the segmentation output of the\nupstream network is the Region-of-Interest (RoI) of the\ndownstream network. The advantage of this practice is\nto avoid the interference caused by the unbalanced data. The introduction of astropic convolution and the manu-\nally cropped input e\u000bectively reduces the amount of net-\nwork parameters. But there are two disadvantages: First\nof all, the segmentation e\u000bect of the downstream network\nis heavily dependent on the performance of the upstream\nnetwork. Second, only the upstream segmentation result\nis considered as the input so that the downstream net-\nwork cannot use other image areas as auxiliary informa-\ntion, which is not conducive to other tasks such as tumor\nlocation detection. Similarly, Hua et al. [113] also pro-\nposed a network cascade based on the physical inclusion\ncharacteristics of tumor. Unlike Wang et al. [46], [113]replaced the cascade unit with a V-Net, which is suitable\nfor 3D segmentation to improve performance. Fang et al. [112] trained two networks to act as upstream networks at\nthe same time according to di\u000berent organisational char-\nacteristics highlighted by di\u000berent modalities, respectively\ntraining for Flair and T1ce, and then the results of the two\nupstream networks can be passed to the downstream net-\nwork for \fnal \fne segmentation. Jia et al. [124] replaced\nupstream and downstream networks with HRNet [125] to\npreserve maximum spatial resolutions. Combining 3D networks for cascading can bring better\nsegmentation performance, but the combination of mul-\ntiple 3D networks requires a large amount of parameters\nand high computational resources. In response to this,\nLi [114] proposed a cascading model that mixes 2D and\n3D networks. 2D networks learn from multi views of a\nvolume to obtain the segmentation mask of the whole tu-\nmor. Then, the whole tumor mask and the original 3D\nvolume are fed to the downstream 3D U-Net.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 21, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.05928853754940712, "word_count": 506, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000020", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000022"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000022", "content": "2D networks learn from multi views of a\nvolume to obtain the segmentation mask of the whole tu-\nmor. Then, the whole tumor mask and the original 3D\nvolume are fed to the downstream 3D U-Net. The down-\nstream network pairs tumor core and enhancing tumor for\n\fne segmentation. Li et al. [126] also adopted a sim-\nilar method by connecting multiple U-Nets in series for\ncoarse-to-\fne segmentation. The segmentation results at\neach stage is associated with di\u000berent loss functions. Vu\net al. [127] further introduced dense connection between\nthe upstream and downstream networks to enhance fea-\nture expression. The two-stage cascaded U-Net designed\nby Jiang et al. [44] has been further enhanced at the out-\nput end. In addition to the single network architecture,\nthey also tried two di\u000berent segmentation modules (inter-\npolation and deconvolution) at the output end. In addition to coarse-to-\fne segmentation, there are\nother attempts to introduce other auxiliary functions. Liu\ndesigned a novel strategy in [128] to pass the segmenta-\ntion result of the upstream network to the downstream\nnetwork. The downstream network reconstructs the orig-\ninal input image according to the segmentation result of\nthe upstream network. The loss of the recovery network is\nalso back-propagated to the upstream segmentation net-\nwork, in order to help the upstream network to outline\nthe tumor area. Cirillo et al. [129] introduced adversarial\ntraining to tumor segmentation. The generator network\nconstitutes the upstream network, and the discriminator\nnetwork is used as the downstream network to determine\nwhether a segmentation map is from ground truth or not. Chen et al. [130] introduced left and right symmetry char-\nacteristics of the brain to the system. The added left and\nright similarity masks at the connection of the upstream\nand downstream networks can improve the robustness of\nnetwork segmentation. 4.1.2. Network Ensemble\nOne main drawback of using a single deep neural net-\nwork is that its performance is heavily in\ruenced by the\nhyper-parameter choices. This refers to a limited gener-\nalisation capability of the deep neural network. Cascaded\nnetwork intends to aggregate multiple networks' output in\n13", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 22, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.08522727272727273, "word_count": 352, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000021", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000023"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000023", "content": "--- Page 14 ---\na coarse-to-\fne strategy, however downstream networks'\nperformance relies on the upstream network, which still\nlimits the capability of a cascaded system. In order to\nachieve a more robust and more generalised tumor seg-\nmentation, the segmentation output from multiple net-\nworks can be aggregated together with a high variance,\nknown as network ensemble. Network ensemble enlarges\nthe hypothesis space of the parameters to be trained by\naggregating multiple networks and avoids falling into local\noptimum caused by data imbalance. Early research works presented in multi-path network\n(Sec. 3.2.1) such as Castillo et al. [76], Kamnitsas et al. [131], [101] can be regarded as a special form of network en-\nsemble, where each path can be treated as a sub-network. The features extracted by the sub-network are then en-\nsembled and processed for the \fnal segmentation. In this\nsection, we pay more attention to explicit ensemble of seg-\nmentation results from multiple sub-networks, rather than\nimplicit ensemble of the features extracted by sub-paths. Ensembles of multiple models and architectures\n(EMMA) [45] is one of the early well-structured works us-\ning ensemble deep neural networks for brain tumor seg-\nmentation. EMMA ensembles segmentation results from\nDeepMedic [131], FCN [40] and U-Net [41] and associ-\nated the \fnal segmentation with the highest con\fdence\nscore. Kao et al. [132] ensembles 26 neural networks for\ntumor segmentation and survival prediction. [132] intro-\nduced brain parcellation atlas to produce a location prior\ninformation for tumor segmentation. Lachinov et al. [133]\nensembles two variant U-Net [42], [47] and a cascaded U-\nNet [134]. The \fnal ensemble result out-performs each\nsingle network 1 \u00002%. Instead of feeding sub-networks with the same input,\nZhao et al. [135] averaged ensembles 3 2D-FCNs where\neach FCN takes di\u000berent view slices as input. Similarly,\nSundaresan et al. [136] averaged ensembles 4 2D-FCNs,\nwhere each FCN is designed for segmenting a speci\fc tu-\nmor region. Chen et al. [137] used a DeconvNet [138]\nto generate a primary segmentation probability map and\nanother multi-scale Convolutional Label Evaluation Net is\nused to evaluate previously generated segmentation maps. False positives can be reduced using both the probability\nmap and the original input image. Hu et al. [139] ensem-\nbles a 3D cascaded U-Net with a multi-modality fusion\nstructure. The proposed two-level U-Net in [139] aims to\noutline the boundary of tumors and the patch-based deep\nnetwork associates tumor voxels with predicted labels. Ensemble can be regarded as a boosting strategy for\nimproving \fnal segmentation results by aggregating re-\nsults from multiple homogeneous networks. The winner\nof the BraTS2018 [47] ensembles 10 models, which further\nboosted the performance with 1% on dice score compared\nwith the best single network segmentation. Similar bene-\n\fts brought by ensembling can be observed from Silva et\nal. [140] as well. BraTS2019 winner [44] also adopted an\nensemble strategy where the \fnal result is generated by\nensembling 12 models, which slightly improves the result(around 0 :6\u00001%) compared with the best single model's\nperformance. 4.2.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 23, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.06, "word_count": 500, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000022", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000024"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000024", "content": "BraTS2019 winner [44] also adopted an\nensemble strategy where the \fnal result is generated by\nensembling 12 models, which slightly improves the result(around 0 :6\u00001%) compared with the best single model's\nperformance. 4.2. Multi-Task Driven Approaches\nMost of the work described above only perform single-\ntask learning, that is, only design and optimise a network\nfor precise segmentation of brain tumors only. The disad-\nvantage of single-task learning is that the training target of\na single-task may ignore the potential information in some\ntasks. Information from related tasks may improve the\nperformance of tumor segmentation. Therefore, in recent\nyears, many research works have started from the perspec-\ntive of multi-task learning, introducing auxiliary tasks on\nthe basis of precise segmentation of brain tumors. The\nmain setting of multi-task learning is a low-level feature\nrepresentation that can be shared among multiple tasks. There are two advantages from the shared representation. One is to share the learnt domain-related information with\neach other through shallow shared representations so as to\npromote learning and to enhance the ability to obtain up-\ndated information. The second is mutual restraint. When\nmulti-task learning performs gradient back-propagation,\nit will take into account the feedback of multiple tasks. Since di\u000berent tasks may have di\u000berent noise patterns, the\nmodel that learns multiple tasks at the same time will learn\na more general representation, which reduces the risk of\nover\ftting and increases the generalisation ability of the\nsystem. Early attempts such as [141] and [142] adapt the idea of\nmulti-task learning and split the brain tumor segmentation\ntask into three di\u000berent sub-region segmentation tasks, i.e. segmenting whole tumor, tumor core and enhancing tumor\nindividually. In [141], the author incorporated three sub-\nregion segmentation tasks into an end-to-end holistic net-\nwork, and exploited the underlying relevance among the\nthree sub-region segmentation tasks. In [142], the author\ndesigned three di\u000berent loss functions, corresponding to\nthe segmentation loss of whole tumor, tumor core and en-\nhancing tumor. In addition, more recent works introduce\nauxiliary tasks di\u000berent from image segmentation. The\nlearnt features from other tasks will support accurate seg-\nmentation. In [102], the author additionally introduces a\nboundary localisation task. The features extracted by the\nshared encoder are not only suitable for tumor segmen-\ntation, but also for tumor boundary localisation. Precise\nboundary localisation can assist in minimising the search-\ning space and de\fning precise boundaries during tumor\nsegmentation. [143] introduced the idea of \frst detecting\nand then segmenting, that is, detecting the location of tu-\nmors, and then performing precise tumor segmentation. Another commonly used auxiliary task is to reconstruct\nthe input data, that is, the learnt feature representation\ncan be restored to the original input by an auxiliary de-\ncoder. [47] is the \frst method to introduce reconstruction\nas an auxiliary task to brain tumor segmentation. [144] in-\ntroduced two auxiliary tasks, reconstruction and enhance-\nment, to further enhance the ability of feature represen-\n14", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 24, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.06109979633401221, "word_count": 491, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000023", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000025"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000025", "content": "--- Page 15 ---\nFigure 10: The structure of multi-task networks for brain tumor segmentation. Image courtesy of [47]. The shared encoder learns generalised\nfeature representation and the reconstruction decoder performs multi-task as regularisation. tation. [145] introduced three auxiliary tasks, including\nreconstruction, edge segmentation and patch comparison. These works regard the auxiliary task as a regularization\nto the main brain tumor segmentation task. Most multi-\ntask designs use shared encoder to extract features and\nindependent decoders to process di\u000berent tasks. From the\nperspective of parameter update, the role of auxiliary task\nis to further regularize shared encoder's parameter. Dif-\nferent from L1 or L2 that explicitly regularize parameter\nnumbers and values, the auxiliary task shared low-level\nsub-space with main task. During training, auxiliary task\nis helpful for the network to train in the direction that\nsimultaneously optimize the auxiliary task and the main\nsegmentation task, which reduces the search space of the\nparameters, makes the extracted features more generalized\nfor accurate segmentation [146], [147], [148], [149]. 4.3. Customised Loss Function Driven Approaches\nDuring network training, the gradient is likely domi-\nnated by the excessively large sample if we use an im-\nbalanced dataset. Therefore, a number of works propose\na custom loss function to regulate gradients during the\ntraining of a brain tumor segmentation model. Designing\na custom loss function aims to reduce the weights of the\neasy-to-classify samples in the loss function, whilst increas-\ning the weights of the hard samples, so that the model is\nmore focused on the samples of a small proportion, reduc-\ning the impact of imbalanced datasets. Early research works tend to uses the standard loss func-\ntions, e.g. categorical cross-entropy [39], cross-entropy\n[152], and dice loss [153]. [150] is the \frst attempt to\ncustomise the loss function. In [150], the authors enhance\nthe loss function to give more weights to the edge pix-\nels, which signi\fcantly improve segmentation accuracy atclassifying tumor boundaries. Experimental results show\nthat the weighted loss function for edge pixels helps to\nimprove the performance of segmentation dice by 2 \u00004%. Later on, [102] proposed a customised cross-entropy loss\nfor boundary pixels while using an auxiliary task that in-\ncludes boundary localisation. In [128], the reconstruction\ntask is adopted as regularisation, so the loss function aims\nat improving pixel-wise reconstruction accuracy. In [67],\nthe space loss function was designed to ensure that the\nlearnt features can keep spatial information as much as\npossible. [143] further used a focal loss to deal with imbal-\nanced issues. [104] used a multi-class dice loss, that is, the\nsmaller the proportion of the category, the higher the er-\nror weight during back-propagation. In [85], a multi-scale\nloss function was added to perform in-depth supervision on\nthe features of di\u000berent scales at each stage of the encoder,\nhelping the network to learn the features in multi-scale res-\nolutions that are more conducive to object segmentation. In [112], from the perspective of a modal, two types of\nlosses were designed for T1ce and Flair respectively.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 25, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.05976095617529881, "word_count": 502, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000024", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000026"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000026", "content": "In [85], a multi-scale\nloss function was added to perform in-depth supervision on\nthe features of di\u000berent scales at each stage of the encoder,\nhelping the network to learn the features in multi-scale res-\nolutions that are more conducive to object segmentation. In [112], from the perspective of a modal, two types of\nlosses were designed for T1ce and Flair respectively. [72]\nproposed a weighted combination of the dice loss, the edge\nloss and the mask loss. The result shows that the combined\nlosses can improve dice performance by about 2%. [151]\nalso proposed a combination loss set, which includes the\ncategotical cross-entropy and the soft dice loss. 4.3.1. Summary\nTable 3 shows the results generated by methods focused\non dealing with data imbalance in brain tumor segmen-\ntation. From the above comparison, we can \fnd several\ninteresting observations. 1. From the perspective of the network, the strategy to\nsolve the imbalance problem is mainly to combine the\noutput of multiple networks. Commonly used combi-\n15", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 26, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.22964071856287427, "word_count": 167, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000025", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000027"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000027", "content": "--- Page 16 ---\nTable 3: Comparisons between the methods with the novelty of dealing with the imbalance issue. We categorise each method based on its main novel contribution. In column Input ,\n'P' means the patch and 'I' means the image. ' Dim ' means the dimension of the network. #Nets means the number of the network candidates. In column Connection , 'C' means\nthe cascade connection and 'E' means the network ensemble. In column Task , 'S' means the segmentation task, 'G' means the modality generation task, 'C' means the classi\fcation\ntask, 'B' means the boundary segmentation task, 'R' means the input reconstruction task. In column Loss , 'CE' means the cross-entropy loss, 'TV' means the total variation loss and\n'KL' means the KL-divergence, 'CPC' means the contrastive predictive coding loss. In column Dice andHausdor\u000b , 'WT' means whole tumor, 'TC' means tumor core and 'ET' means\nenhancing tumor. Column Dataset indicates the associated dataset with the reported segmentation performance. In column Type, 'CV' means the cross-validation on BraTS training\nset, 'V' means the BraTS validation set and 'T' means the BraTS test set. '-' means the entry was not reported in the original paper.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 27, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.0, "word_count": 198, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000026", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000028"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000028", "content": "In column Type, 'CV' means the cross-validation on BraTS training\nset, 'V' means the BraTS validation set and 'T' means the BraTS test set. '-' means the entry was not reported in the original paper. Methods Input Dim #Nets Connection Task LossDice Hausdor\u000b Dataset\nWT TC ET WT TC ET Year Type\nMulti\nNetworks\nDriven\nApproaches[46] P 3D 3 C S Dice 0.9 0.84 0.78 3.89 6.48 3.28 2017 V\n[113] P 3D 5 C+E S Focal 0.9 0.84 0.77 5.18 6.28 3.51 2018 V\n[112] I 2D 2 E S - 0.86 0.73 0.72 7.5 9.5 5.7 2018 V\n[124] I 3D 2 C S Dice + CE 0.91 0.85 0.79 4.18 4.97 26.57 2020 V\n[114] I 3D 5 C+E S Dice 0.88 0.79 0.72 29.21 11.06 7.93 2018 V\n[127] I 3D 3 C S Dice 0.9 0.81 0.78 4.32 6.28 3.7 2019 V\n[44] I 3D 2 C S Dice 0.91 0.86 0.8 4.26 5.43 3.14 2019 V\n[128] I 2D 2 C G+S L1+TV - - - - - - - -\n[129] I 3D 2 C G+S L2+Dice 0.89 0.79 0.75 6.39 14.07 36 2020 V\n[45] I 3D 3 E S CE+IoU 0.9 0.8 0.74 4.23 6.56 4.5 2017 V\n[133] I 3D 3 E S Dice+CE 0.9 0.84 0.76 - - - 2019 V\n[135] P 2D 3 E S - 0.89 0.79 0.75 - - - 2017 V\n[136] P 2D 4 E S Dice+CE 0.89 0.77 0.77 4.4 15.3 29.4 2020 V\n[139] I 2D 3 C S+C Dice 0.85 0.7 0.65 25.24 21.45 17.98 2017 V\n[140] P 2D 3 C S CE 0.91 0.81 0.76 4.34 9.39 27.16 2020 V\nMulti\nTasks\nDriven\nApproaches[141] P 3D 2 C+E S+C - 0.91 0.86 0.81 4.17 6.54 2.71 2018 V\n[130] - - 1 - S+Sim CE+Focal 0.85 0.68 0.58 - - - 2015 V\n[142] I 2D 1 - S CE 0.88 0.71 0.73 - - - 2015 T\n[102] I 2D 1 - S+B CE 0.89 0.72 0.73 - - - 2015 T\n[47] I 3D 10 E S+R Dice+L2+KL 0.91 0.87 0.82 4.52 6.85 3.92 2018 V\n[144] P 3D 1 - S+R+C Dice+L2+KL 0.85 0.78 0.75 7.98 8.25 5.76 2019 V\n[145] I 3D 1 - S+R+B L2+KL+Dice+CE+CPC 0.92 0.88 0.88 12.4 16.09 8.71 2017 Sub\nCustomized\nLoss\nFunction\nDriven\nApproaches[150] P 2D 1 - S L1+L2+CE 0.87 0.75 0.71 - - - 2016 T\n[67] I 2D 1 - S Dice 0.88 0.8 0.76 6.49 6.68 21.39 2020 V\n[143] I 3D 10 E S Dice+Focal+CE 0.9 0.84 0.78 5.68 9.57 24.02 2020 V\n[104] I 3D 1 - S Dice 0.9 0.8 0.73 7 9.48 4.55 2017 V\n[85] I 3D 1 - S CE 0.9 0.75 0.71 4.16 8.65 6.98 2017 V\n[72] I 3D 1 - S Dice+Edge+Mask 0.9 0.82 0.78 5.41 7.26 5.282 2019 V\n[151] I 2D 5 E S Dice 0.92 0.88 0.87 4.23 5.77 8.18 2019 V16", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 28, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.0, "word_count": 499, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000027", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000029"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000029", "content": "--- Page 17 ---\nFigure 11: The illustration of cross-modality feature learning framework. Image courtesy from [154]. nation methods include network cascade and network\nensemble. But these strategies all depend on the per-\nformance of each network. The consumption of the\ncomputing resources is also increased proportionally\nto the number of the network candidates. 2. From the perspective of a task, the strategy to solve\nthe imbalance problem is to set up auxiliary tasks for\nthe regulating networks so that the networks can make\nfull use of the existing data and learn more generalised\nfeatures that are bene\fcial to the auxiliary tasks as\nwell as the segmentation task. 3. From the perspective of the loss function, the strategy\nto solve the imbalance problem is to use a custom loss\nfunction or an auxiliary loss function. By weighting\nthe hard samples, the networks are regulated to pay\nmore attention to the small data. 5. Utilising Multi Modality Information\nMulti-modality imaging has played a key role in medi-\ncal image analysis and applications. Di\u000berent modalities of\nMRI emphasise on di\u000berent tissues. E\u000bective use of multi-\nmodality information is one of the key factors in MRI-\nbased brain tumor segmentation. According to the number\nof the available modalities, we divide the multi-modality\nbrain tumor segmentation into two scenes: leveraging in-\nformation based on multiple modalities and limited infor-\nmation processing with missing modality. 5.1. Learning with multiple modalities\nIn this paper, we follow the BraTS competition stan-\ndard, that is, multi-modality refers the input data modali-\nties include but not limit to T1, T1ce, T2, and Flair. In or-\nder to e\u000bectively use multi-modality information, existing\nworks focus on e\u000bectively learning multi-modality infor-\nmation. The designed learning methods can be classi\fed\ninto three categories based on their purposes: Learning\nto Rank ,Learning to Pair andLearning to Fuse . Figure 12: The structure of the modality-aware feature embedding\nmodule. Image courtesy of [50]. Learning to Rank Modalities In multi-modality pro-\ncessing, the existing data modality is sorted by relevance\nbased on the learning task, so that the network can focus\non learning the modality with high relevance. This de\f-\nnition can be re-named as modality-task modeling. Early\nwork from [82] can be treated as basic learning to rank for-\nmation. In [82], the author transformed each modality to\na single CNN. In [82], each CNN corresponds to a di\u000berent\nmodality and the features extracted by CNN are indepen-\ndent of each other. The loss returned by the \fnal classi\fer\nis similar to the scoring of the input data and the seg-\nmentation is undertaken according to the score. A similar\nprocessing method was used in [50]. For each of the two\nmodalities, two independent networks were used for mod-\neling relationship matching, and the parameters of each\nnetwork are a\u000bected by the in\ruence of di\u000berent supervi-\nsion losses. [154] extracted features of di\u000berent embedding\nmodalities (as shown in Fig.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 29, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.11012024048096192, "word_count": 499, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000028", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000030"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000030", "content": "For each of the two\nmodalities, two independent networks were used for mod-\neling relationship matching, and the parameters of each\nnetwork are a\u000bected by the in\ruence of di\u000berent supervi-\nsion losses. [154] extracted features of di\u000berent embedding\nmodalities (as shown in Fig. 11), modeled the relationship\nbetween the modalities and the segmentation of di\u000berent\ntumor sub-regions, so that the data of di\u000berent modali-\nties were weighted and sorted corresponding to individual\n17", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 30, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.0, "word_count": 79, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000029", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000031"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000031", "content": "--- Page 18 ---\nFigure 13: The structure of the modality correlation module. Image\ncourtesy of [80]. tasks. Learning to Pair Modalities Learning to rank\nmodalities refers to the sorting of the modality-task re-\nlation for a certain segmentation task. Another commonly\nused modeling is the modality-modality pairing, which se-\nlects the best combination from multi-modality data to\nachieve precise segmentation. [155] is one of the early\nworks to model the modality-modality relationship. The\nauthors paired every two modalities and sent all the pair-\ning combinations to the downstream network. [154] fur-\nther strengthens the modality-modality pairing relation-\nship through the cross-modal feature transition module\nand the modal pairing module. In the cross-modality fea-\nture transition module, the authors converted the input\nand output from one modality's data to the concatenation\nof a modality pair. In the cross-modality feature fusion\nmodule, the authors converted the single-modality feature\nlearning to the single-modality-pair feature learning, which\npredicts the segmentation masks of each single-modality-\npair. Learning to Fuse Modalities More recent works fo-\ncus on learning to fuse multi-modality. Di\u000berent from\nthe modality ranking and pairing, modality fusion is to\nfuse features from each modality for accurate segmenta-\ntion. The early fusion method is relatively simple, usu-\nally concatenates or adds features learned from di\u000berent\nmodalities. In [82], the authors used 4 networks to ex-\ntract features from each modality and concatenates the\nextracted modality aware features. The features after con-\ncatenation are sent to Random Forest to classify the cen-\ntral pixel of the input patch. In [112], features from T1ce\nand Flair were added and sent to the downstream net-\nwork for entire tumor segmentation. Similarly, in [154],\nmodality aware feature extraction is performed and sent\nto the downstream network for further learning. These\ntwo fusion methods do not introduce additional param-\neters and are very simple and e\u000ecient. In [154], even\nthough the authors fused the features from more complex\ncross-modal feature pairing and single-modal feature pair-\ning modules. In addition, there are other works such as\n[152] and [155] that used additional convolutional modules\nto combine and learn features from di\u000berent modalities soas to accomplish modality fusion. Although concatenation and addition are used, these\ntwo fusion methods do not change the semantics of learned\nfeatures and cannot highlight or suppress features. To\ntackling this problem, many research works in recent\nyears have adopted attention mechanisms to strengthen\nthe learnt features. [65], [67], [66] and [68] used a spatial\nand channel attention based fusion module. The proposed\nattention mechanism highlights useful features and sup-\npresses redundant features, resulting in accurate segmen-\ntation. 5.2. Dealing with Missing Modalities\nThe modality learning methods mentioned above work\nin the multi-modality scene. For example, in BraTS, we\nobtain the data of four modalities: T1, T1ce, T2, and\nFLAIR. However, in actual application scenarios, it is\nvery di\u000ecult to obtain complete and high-quality multi-\nmodality datasets, refers to as missing modality scenarios. [156] is one of the earliest works targeting learning under\nmissing modality.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 31, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.0, "word_count": 502, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000030", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000032"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000032", "content": "However, in actual application scenarios, it is\nvery di\u000ecult to obtain complete and high-quality multi-\nmodality datasets, refers to as missing modality scenarios. [156] is one of the earliest works targeting learning under\nmissing modality. The authors in [156] constructed the\nonly available modal T1 and used generative adversarial\nnetworks to generate the missed modalities. In [156], the\nauthors used the existing T1 modality as input to gener-\nate Flair modality. The generated Flair data is sent as a\nsupplement with the original T1 data to the downstream\nsegmentation network. [157], [80] learnt the implicit re-\nlationship between modalities and examined all possible\nmissing scenarios. The results show that multi-modality\nhave an important in\ruence on accurate segmentation. In\n[158], the intensity correction algorithm was proposed for\ndi\u000berent scenarios of the single modality input. In this\nframework, the intensity query and correction of the data\nof multiple modalities makes it easier to distinguish the\ntumor and non-tumor regions in the synthetic data. 5.2.1. Summary\nTable 4 shows the results generated by methods focused\nlearning with multi-modality in deep learning based brain\ntumor segmentation. We can collect several common ob-\nservations in utilising the information from multi modali-\nties. 1. For task-modality modeling, learning to rank modali-\nties can help the network choose the most relative and\nconducive modality for accurate segmentation. Most\nof the research works model the implicit ranking while\nlearning the modality aware features. 2. For modality-modality modeling, learning to pair\nmodalities can help the network \fnd the most suitable\nmodality combination for segmentation. However, ex-\nisting pairing works show modality pairs through ex-\nhaustive combination with large computing resources. 3. The fusion of multi-modality information can improve\nthe expressive ability and generalisation of features. Existing fusion methods have their own advantages\nand disadvantages. Addition or concatenation does\n18", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 32, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.19933774834437087, "word_count": 302, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000031", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000033"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000033", "content": "--- Page 19 ---\nTable 4: Comparison between the methods with the novelty of learning with multi-modality. We categorise each method based on its main novel contribution. In column Input , 'P'\nmeans the patch and 'I' means the image. ' Dim ' means the dimension of the network. Column 'Learning To' means the learning task of multi-modality, where 'R' means learning\nto rank, 'P' means learning to pair, 'F' means learning to fuse, 'G' means learning to generate missing modality, 'Fw/M' means fuse with missing modalities. In column Fusion ,\n'Concate' means concatenation, 'Conv' means the convolution module, 'Add' mean addition, 'S Att' means spatial attention, 'C Att' means channel attention. In column Task , 'S'\nmeans segmentation task, 'G' means modality generation task. In column Loss , 'CE' means cross-entropy loss, 'Adv' means adversarial loss, 'CC' means cycle consistency loss and\n'MAE' means mean absolute square loss. In column Dice andHausdor\u000b , 'WT' means whole tumor, 'TC' means tumor core and 'ET' means enhancing tumor. Column Dataset\nindicates the associated dataset with the reported segmentation performance. In column Type, 'CV' means cross-validation on the BraTS training set, 'V' means the BraTS validation\nset and 'Sub' means the manually divided subset from training set. '-' means the entry was not reported in the original paper.\nMethods Input Dim Learning To Fusion Task LossDice Hausdor\u000b Dataset\nWT TC ET WT TC ET Year Type\nLearning\nwith\nComplete\nModalities[82] P 2D R+F Concate S - - - - - - - - -\n[152] I 2D F Conv S CE 0.85 0.68 0.69 - - - 2015 V\n[155] I 2D P+F Conv S Focal 0.88 0.71 0.75 2017 V\n[112] I 2D F Add S - 0.86 0.73 0.72 7.5 9.5 5.7 2018 V\n[66] I 2D F S Att + C Att S Dice - - - - - - - -\n[65] P 3D F S Att + C Att S - 0.9 0.79 0.7 6.29 8.76 7.05 2019 V\n[67] I 2D F S Att + C Att S Dice 0.88 0.8 0.76 6.49 6.68 21.39 2020 V\n[50] P 3D R+P+F Concate + Add S Adv+CC 0.9 0.84 0.79 5 6.37 3.99 2018 V\n[154] P 3D R+F Concate G+S Dice+T-Test 0.9 0.82 0.78 5.73 9.27 3.57 2020 V\n[68] I 3D F S Att + C Att S Dice 0.87 0.79 0.74 7.54 7.68 6.1 2017 CV\nDealing\nwith\nMissing\nModalities[156] I 3D G - G+S L1 0.68 0.72 - - - - 2015 Sub\n[80] I 3D Fw/M S Att + C Att S Dice+MAE 0.87 0.72 0.73 6.7 9.3 6.3 2019 V\n[157] I 3D Fw/M S Att + C Att S Dice+MAE 0.88 0.79 0.69 - - - 2018 CV\n[158] I 3D Fw/M - S - 0.91 0.85 0.78 4.46 5.26 3.69 2019 V\n19", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 33, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "paragraph", "importance_score": 0.0, "word_count": 474, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000032", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000034"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000034", "content": "--- Page 20 ---\nTable 5: Opensourced projects from deep learning based brain tumor segmentation. where '3rd Party' means the code is re-implemented by\na third party based on the associated paper.\nPaper Title Code Link\nBrain tumor segmentation with Deep Neural Networks(3rd Party) https://github.com/naldeborgh7575/\nbrain segmentation\nDeepMedic on Brain Tumor Segmentation https://github.com/deepmedic/deepmedic\nMulti-dimensional Gated Recurrent Units for Brain Tu-\nmor Segmentationhttps://github.com/zubata88/mdgru\nVolumetric Multimodality Neural Network For Brain\nTumor Segmentationhttps://github.com/BCV-Uniandes/BCVbrats\nBrain Tumor Segmentation and Radiomics Survival\nPrediction: Contribution to the BRATS 2017 Challenge(3rd Party) https://github.com/pykao/Modi\fed-3D-\nUNet-Pytorch\nResidual Encoder and Convolutional Decoder Neural\nNetwork for Glioma Segmentationhttps://github.com/kamleshpawar17/BratsNet-2017\nAutomatic Brain Tumor Segmentation Using Cascaded\nAnisotropic Convolutional Neural Networkshttps://github.com/taigw/brats18 docker\nNo New-Net https://github.com/MIC-DKFZ/nnUNet\n3D MRI Brain Tumor Segmentation Using Autoencoder\nRegularization(3rd Party) https://github.com/IAmSuyogJadhav/3d-\nmri-brain-tumor-segmentation-using-autoencoder-\nregularization\n3D-ESPNet with Pyramidal Re\fnement for Volumetric\nBrain Tumor Image Segmentationhttps://github.com/sacmehta/3D-ESPNet\nOne-pass Multi-task Networks with Cross-task Guided\nAttention for Brain Tumor Segmentationhttps://github.com/chenhong-zhou/OM-Net\nMulti-step Cascaded Networks for Brain Tumor Seg-\nmentationhttps://github.com/JohnleeHIT/Brats2019\nAn Ensemble of 2D Convolutional Neural Network for\n3D Brain Tumor Segmentationhttps://github.com/kamleshpawar17/Brats19\nKnowledge Distillation for Brain Tumor Segmentation https://github.com/lachinov/brats2019\nLabel-E\u000ecient Multi-Task Segmentation using Con-\ntrastive Learninghttps://github.com/pfnet-research/label-e\u000ecient-\nbrain-tumor-segmentation\nVox2Vox: 3D-GAN for Brain Tumour Segmentation https://github.com/mdciri/Vox2Vox\nBrain tumor segmentation with self-ensembled, deeply-\nsupervised 3D U-net neural networks: a BraTS 2020\nchallenge solution.https://github.com/lescienti\fk/open brats2020\nBrain tumour segmentation using a triplanar ensemble\nof U-Nets on MR imageshttps://git.fmrib.ox.ac.uk/vaanathi/truenet tumseg\nA Two-Stage Cascade Model with Variational Autoen-\ncoders and Attention Gates for MRI Brain Tumor Seg-\nmentationhttps://github.com/shu-hai/two-stage-VAE-Attention-\ngate-BraTS2020\nHDC-Net: Hierarchical Decoupled Convolution Net-\nwork for Brain Tumor Segmentationhttps://github.com/luozhengrong/HDC-Net\n20", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 34, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "paragraph", "importance_score": 0.242914979757085, "word_count": 247, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000033", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000035"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000035", "content": "--- Page 21 ---\nnot introduce additional parameters, but lacks the\nphysical expression of features. Using a small net-\nwork, an attention module can optimise feature ex-\npression, but introduce additional parameters and\ncomputational cost. 4. Missing modalities are one of the common scenes in\nclinical imaging. Existing works focus on the per-\nspective of generation, using existing modality data\nto generate missing modalities. However, the perfor-\nmance and quality of the generator modal heavily re-\nlies on the quality of the existing modality data. 6. Conclusion\nApplying various deep learning methods to brain tumor\nsegmentation is an invaluable and challenging task. Au-\ntomated image segmentation bene\fts several aspects due\nto the powerful feature learning ability of deep learning\ntechniques. In this paper, we have investigated relevant\ndeep learning based brain tumor segmentation methods\nand presented a comprehensive survey. We structurally\ncategorised and summarised the deep learning based brain\ntumor segmentation methods. We have widely investi-\ngated this task and discussed several key aspects such as\nmethods' pros and cons, designing motivation and perfor-\nmance evaluation. Acknowledgement\nThis work was funded by the Chine Scholarship Coun-\ncil and Graduate Teaching Assistantship of University of\nLeicester. Yaochu Jin is supported by an Alexander von\nHumboldt Professorship endowed by the German Fed-\neral Ministry for Education and Research. The authors\nthank Prof. Guotai Wang, Prof. Dingwen Zhang and Dr.\nTongxue Zhou for their detailed suggestions and discus-\nsions. References\n[1] K. Doi, Computer-aided diagnosis in medical imaging: histor-\nical review, current status and future potential, Computerized\nmedical imaging and graphics 31 (4-5) (2007) 198{211. [2] M. Lavin, M. Nathan, System and method for managing pa-\ntient medical records, uS Patent 5,772,585 (Jun. 30 1998). [3] R. H. Taylor, A. Menciassi, G. Fichtinger, P. Fiorini,\nP. Dario, Medical robotics and computer-integrated surgery,\nin: Springer handbook of robotics, Springer, 2016, pp. 1657{\n1684. [4] G. Litjens, T. Kooi, B. E. Bejnordi, A. A. A. Setio, F. Ciompi,\nM. Ghafoorian, J. A. van der Laak, B. Van Ginneken, C. I.\nS\u0013 anchez, A survey on deep learning in medical image analysis,\nMedical image analysis 42 (2017) 60{88. [5] D. N. Louis, A. Perry, G. Reifenberger, A. Von Deimling,\nD. Figarella-Branger, W. K. Cavenee, H. Ohgaki, O. D.\nWiestler, P. Kleihues, D. W. Ellison, The 2016 world health\norganization classi\fcation of tumors of the central nervous sys-\ntem: a summary, Acta neuropathologica 131 (6) (2016) 803{\n820. [6] U. Baid, S. Ghodasara, S. Mohan, M. Bilello, E. Calabrese,\nE. Colak, K. Farahani, J. Kalpathy-Cramer, F. C. Kitamura,\nS. Pati, et al., The rsna-asnr-miccai brats 2021 benchmark\non brain tumor segmentation and radiogenomic classi\fcation,\narXiv preprint arXiv:2107.02314. [7] S. Bakas, H. Akbari, A. Sotiras, M. Bilello, M. Rozycki, J. S.\nKirby, J. B. Freymann, K. Farahani, C. Davatzikos, Advancing\nthe cancer genome atlas glioma mri collections with expert\nsegmentation labels and radiomic features, Scienti\fc data 4 (1)\n(2017) 1{13.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 35, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.3351851851851852, "word_count": 486, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000034", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000036"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000036", "content": "[7] S. Bakas, H. Akbari, A. Sotiras, M. Bilello, M. Rozycki, J. S.\nKirby, J. B. Freymann, K. Farahani, C. Davatzikos, Advancing\nthe cancer genome atlas glioma mri collections with expert\nsegmentation labels and radiomic features, Scienti\fc data 4 (1)\n(2017) 1{13. [8] B. H. Menze, A. Jakab, S. Bauer, J. Kalpathy-Cramer,\nK. Farahani, J. Kirby, Y. Burren, N. Porz, J. Slotboom,\nR. Wiest, et al., The multimodal brain tumor image segmenta-\ntion benchmark (brats), IEEE transactions on medical imaging\n34 (10) (2014) 1993{2024. [9] M. Gha\u000bari, A. Sowmya, R. Oliver, Automated brain tumor\nsegmentation using multimodal brain scans: a survey based\non models submitted to the brats 2012{2018 challenges, IEEE\nreviews in biomedical engineering 13 (2019) 156{168. [10] L. Kapoor, S. Thakur, A survey on brain tumor detection us-\ning image processing techniques, in: 2017 7th international\nconference on cloud computing, data science & engineering-\ncon\ruence, IEEE, 2017, pp. 582{585. [11] M. Hameurlaine, A. Moussaoui, Survey of brain tumor seg-\nmentation techniques on magnetic resonance imaging, Nano\nBiomedicine and Engineering 11 (2) (2019) 178{191. [12] N. Gordillo, E. Montseny, P. Sobrevilla, State of the art survey\non mri brain tumor segmentation, Magnetic resonance imaging\n31 (8) (2013) 1426{1438. [13] J. Liu, M. Li, J. Wang, F. Wu, T. Liu, Y. Pan, A survey of mri-\nbased brain tumor segmentation methods, Tsinghua Science\nand Technology 19 (6) (2014) 578{595. [14] J. Nalepa, M. Marcinkiewicz, M. Kawulok, Data augmentation\nfor brain-tumor segmentation: a review, Frontiers in compu-\ntational neuroscience 13 (2019) 83. [15] J. Bernal, K. Kushibar, D. S. Asfaw, S. Valverde, A. Oliver,\nR. Mart\u0013 \u0010, X. Llad\u0013 o, Deep convolutional neural networks for\nbrain image analysis on magnetic resonance imaging: a review,\nArti\fcial intelligence in medicine 95 (2019) 64{81. [16] Z. Akkus, A. Galimzianova, A. Hoogi, D. L. Rubin, B. J. Erick-\nson, Deep learning for brain mri segmentation: state of the art\nand future directions, Journal of digital imaging 30 (4) (2017)\n449{459. [17] A. Esteva, A. Robicquet, B. Ramsundar, V. Kuleshov, M. De-\nPristo, K. Chou, C. Cui, G. Corrado, S. Thrun, J. Dean, A\nguide to deep learning in healthcare, Nature medicine 25 (1)\n(2019) 24{29. [18] L. Liu, W. Ouyang, X. Wang, P. Fieguth, J. Chen, X. Liu,\nM. Pietik\u007f ainen, Deep learning for generic object detection: A\nsurvey, International journal of computer vision 128 (2) (2020)\n261{318. [19] Y. LeCun, Y. Bengio, G. Hinton, Deep learning, nature\n521 (7553) (2015) 436. [20] J. Gu, Z. Wang, J. Kuen, L. Ma, A. Shahroudy, B. Shuai,\nT. Liu, X. Wang, G. Wang, J. Cai, et al., Recent advances in\nconvolutional neural networks, Pattern Recognition 77 (2018)\n354{377. [21] J. Bernal, K. Kushibar, D. S. Asfaw, S. Valverde, A. Oliver,\nR. Mart\u0013 \u0010, X. Llad\u0013 o, Deep convolutional neural networks for\nbrain image analysis on magnetic resonance imaging: a review,\nArti\fcial intelligence in medicine. [22] A. Esteva, A. Robicquet, B. Ramsundar, V. Kuleshov, M. De-\nPristo, K. Chou, C. Cui, G. Corrado, S. Thrun, J.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 36, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.17892644135188865, "word_count": 503, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000035", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000037"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000037", "content": "[21] J. Bernal, K. Kushibar, D. S. Asfaw, S. Valverde, A. Oliver,\nR. Mart\u0013 \u0010, X. Llad\u0013 o, Deep convolutional neural networks for\nbrain image analysis on magnetic resonance imaging: a review,\nArti\fcial intelligence in medicine. [22] A. Esteva, A. Robicquet, B. Ramsundar, V. Kuleshov, M. De-\nPristo, K. Chou, C. Cui, G. Corrado, S. Thrun, J. Dean, A\nguide to deep learning in healthcare, Nature Medicine 25 (1)\n(2019) 24{29. [23] I. Goodfellow, Y. Bengio, A. Courville, Deep learning, 2016. [24] H. Lin, S. Jegelka, Resnet with one-neuron hidden layers is a\nuniversal approximator, Advances in Neural Information Pro-\ncessing Systems 31 (2018) 6169{6178. [25] D. Yarotsky, Error bounds for approximations with deep relu\nnetworks, Neural Networks 94 (2017) 103{114. 21", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 37, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.24390243902439024, "word_count": 123, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000036", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000038"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000038", "content": "--- Page 22 ---\n[26] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y. Fu,\nA. C. Berg, Ssd: Single shot multibox detector, in: European\nconference on computer vision, Springer, 2016, pp. 21{37. [27] Y. Chen, J. Joo, Understanding and mitigating annotation\nbias in facial expression recognition, in: Proceedings of the\nIEEE/CVF International Conference on Computer Vision,\n2021, pp. 14980{14991. [28] S. R. Bulo, G. Neuhold, P. Kontschieder, Loss max-pooling\nfor semantic image segmentation, in: 2017 IEEE Conference\non Computer Vision and Pattern Recognition (CVPR), IEEE,\n2017, pp. 7082{7091. [29] Y. Zhu, Z. Yan, Computerized tumor boundary detection us-\ning a hop\feld neural network, IEEE transactions on medical\nimaging 16 (1) (1997) 55{67. [30] M. C. Clark, L. O. Hall, D. B. Goldgof, R. Velthuizen, F. R.\nMurtagh, M. S. Silbiger, Automatic tumor segmentation us-\ning knowledge-based techniques, IEEE transactions on medical\nimaging 17 (2) (1998) 187{201. [31] M. Kaus, S. K. War\feld, A. Nabavi, E. Chatzidakis, P. M.\nBlack, F. A. Jolesz, R. Kikinis, Segmentation of meningiomas\nand low grade gliomas in mri, in: International conference on\nmedical image computing and computer-assisted intervention,\nSpringer, 1999, pp. 1{10. [32] M. Prastawa, E. Bullitt, S. Ho, G. Gerig, A brain tumor seg-\nmentation framework based on outlier detection, Medical im-\nage analysis 8 (3) (2004) 275{283. [33] J. J. Corso, E. Sharon, S. Dube, S. El-Saden, U. Sinha,\nA. Yuille, E\u000ecient multilevel brain tumor segmentation with\nintegrated bayesian model classi\fcation, IEEE transactions on\nmedical imaging 27 (5) (2008) 629{640. [34] M. Wels, G. Carneiro, A. Aplas, M. Huber, J. Hornegger,\nD. Comaniciu, A discriminative model-constrained graph cuts\napproach to fully automated pediatric brain tumor segmenta-\ntion in 3-d mri, in: International Conference on Medical Im-\nage Computing and Computer-Assisted Intervention, Springer,\n2008, pp. 67{75. [35] B. H. Menze, K. Van Leemput, D. Lashkari, M.-A. Weber,\nN. Ayache, P. Golland, A generative model for brain tumor\nsegmentation in multi-modal images, in: International Con-\nference on Medical Image Computing and Computer-Assisted\nIntervention, Springer, 2010, pp. 151{159. [36] A. Krizhevsky, I. Sutskever, G. E. Hinton, Imagenet classi\f-\ncation with deep convolutional neural networks, Advances in\nneural information processing systems 25 (2012) 1097{1105. [37] D. Zikic, Y. Ioannou, M. Brown, A. Criminisi, Segmentation of\nbrain tumor tissues with convolutional neural networks, Pro-\nceedings MICCAI-BRATS 36 (2014) 36{39. [38] M. Havaei, A. Davy, D. Warde-Farley, A. Biard, A. Courville,\nY. Bengio, C. Pal, P.-M. Jodoin, H. Larochelle, Brain tumor\nsegmentation with deep neural networks, Medical image anal-\nysis 35 (2017) 18{31. [39] S. Pereira, A. Pinto, V. Alves, C. A. Silva, Brain tumor seg-\nmentation using convolutional neural networks in mri images,\nIEEE transactions on medical imaging 35 (5) (2016) 1240{\n1251. [40] J. Long, E. Shelhamer, T. Darrell, Fully convolutional net-\nworks for semantic segmentation, in: Proceedings of the IEEE\nconference on computer vision and pattern recognition, 2015,\npp. 3431{3440. [41] O. Ronneberger, P. Fischer, T. Brox, U-net: Convolutional\nnetworks for biomedical image segmentation, in: Interna-\ntional Conference on Medical image computing and computer-\nassisted intervention, Springer, 2015, pp. 234{241.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 38, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.11741682974559686, "word_count": 511, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000037", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000039"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000039", "content": "[41] O. Ronneberger, P. Fischer, T. Brox, U-net: Convolutional\nnetworks for biomedical image segmentation, in: Interna-\ntional Conference on Medical image computing and computer-\nassisted intervention, Springer, 2015, pp. 234{241. [42] F. Isensee, P. Kickingereder, W. Wick, M. Bendszus, K. H.\nMaier-Hein, No new-net, in: International MICCAI Brainle-\nsion Workshop, Springer, 2018, pp. 234{244. [43] X. Zhao, Y. Wu, G. Song, Z. Li, Y. Zhang, Y. Fan, A deep\nlearning model integrating fcnns and crfs for brain tumor seg-\nmentation, Medical image analysis 43 (2018) 98{111. [44] Z. Jiang, C. Ding, M. Liu, D. Tao, Two-stage cascaded u-net:\n1st place solution to brats challenge 2019 segmentation task,in: International MICCAI Brainlesion Workshop, Springer,\n2019, pp. 231{241. [45] K. Kamnitsas, W. Bai, E. Ferrante, S. McDonagh, M. Sin-\nclair, N. Pawlowski, M. Rajchl, M. Lee, B. Kainz, D. Rueck-\nert, et al., Ensembles of multiple models and architectures for\nrobust brain tumour segmentation, in: International MICCAI\nbrainlesion workshop, Springer, 2017, pp. 450{462. [46] G. Wang, W. Li, S. Ourselin, T. Vercauteren, Automatic brain\ntumor segmentation using cascaded anisotropic convolutional\nneural networks, in: International MICCAI brainlesion work-\nshop, Springer, 2017, pp. 178{190. [47] A. Myronenko, 3d mri brain tumor segmentation using au-\ntoencoder regularization, in: International MICCAI Brainle-\nsion Workshop, Springer, 2018, pp. 311{320. [48] C. Zhou, C. Ding, X. Wang, Z. Lu, D. Tao, One-pass multi-task\nnetworks with cross-task guided attention for brain tumor seg-\nmentation, IEEE Transactions on Image Processing 29 (2020)\n4516{4529. [49] C. H. Sudre, W. Li, T. Vercauteren, S. Ourselin, M. J. Cardoso,\nGeneralised dice overlap as a deep learning loss function for\nhighly unbalanced segmentations, in: Deep learning in medical\nimage analysis and multimodal learning for clinical decision\nsupport, Springer, 2017, pp. 240{248. [50] D. Zhang, G. Huang, Q. Zhang, J. Han, J. Han, Y. Yu, Cross-\nmodality deep feature learning for brain tumor segmentation,\nPattern Recognition 110 (2021) 107562. [51] T. Zhou, S. Canu, P. Vera, S. Ruan, Latent correlation repre-\nsentation learning for brain tumor segmentation with missing\nmri modalities, IEEE Transactions on Image Processing 30\n(2021) 4263{4274. doi:10.1109/TIP.2021.3070752 . [52] A. de Brebisson, G. Montana, Deep neural networks for\nanatomical brain segmentation, in: Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition\nWorkshops, 2015, pp. 20{28. [53] B. Patenaude, S. M. Smith, D. N. Kennedy, M. Jenkinson, A\nbayesian model of shape and appearance for subcortical brain\nsegmentation, Neuroimage 56 (3) (2011) 907{922. [54] Q. Dou, H. Chen, L. Yu, L. Shi, D. Wang, V. C. Mok,\nP. A. Heng, Automatic cerebral microbleeds detection from\nmr images via independent subspace analysis based hierarchi-\ncal features, in: Engineering in Medicine and Biology Society\n(EMBC), 2015 37th Annual International Conference of the\nIEEE, IEEE, 2015, pp. 7933{7936. [55] Q. Dou, H. Chen, L. Yu, L. Zhao, J. Qin, D. Wang, V. C. Mok,\nL. Shi, P.-A. Heng, Automatic detection of cerebral microb-\nleeds from mr images via 3d convolutional neural networks,\nIEEE transactions on medical imaging 35 (5) (2016) 1182{\n1195.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 39, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.12072434607645875, "word_count": 497, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000038", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000040"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000040", "content": "[55] Q. Dou, H. Chen, L. Yu, L. Zhao, J. Qin, D. Wang, V. C. Mok,\nL. Shi, P.-A. Heng, Automatic detection of cerebral microb-\nleeds from mr images via 3d convolutional neural networks,\nIEEE transactions on medical imaging 35 (5) (2016) 1182{\n1195. [56] M. Ghafoorian, N. Karssemeijer, T. Heskes, M. Bergkamp,\nJ. Wissink, J. Obels, K. Keizer, F.-E. de Leeuw, B. van Gin-\nneken, E. Marchiori, et al., Deep multi-scale location-aware\n3d convolutional neural networks for automated detection of\nlacunes of presumed vascular origin, NeuroImage: Clinical 14\n(2017) 391{399. [57] H.-I. Suk, C.-Y. Wee, S.-W. Lee, D. Shen, State-space model\nwith deep learning for functional dynamics estimation in\nresting-state fmri, NeuroImage 129 (2016) 292{307. [58] H.-I. Suk, D. Shen, Deep ensemble sparse regression network\nfor alzheimer's disease diagnosis, in: International Workshop\non Machine Learning in Medical Imaging, Springer, 2016, pp. 113{121. [59] W. H. Pinaya, A. Gadelha, O. M. Doyle, C. Noto, A. Zugman,\nQ. Cordeiro, A. P. Jackowski, R. A. Bressan, J. R. Sato, Us-\ning deep belief network modelling to characterize di\u000berences\nin brain morphometry in schizophrenia, Scienti\fc reports 6\n(2016) 38897. [60] Y. Yoo, L. W. Tang, T. Brosch, D. K. Li, L. Metz, A. Tra-\nboulsee, R. Tam, Deep learning of brain lesion patterns for\npredicting future disease activity in patients with early symp-\ntoms of multiple sclerosis, in: Deep Learning and Data Label-\ning for Medical Applications, Springer, 2016, pp. 86{94. 22", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 40, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.5234439834024897, "word_count": 241, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000039", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000041"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000041", "content": "--- Page 23 ---\n[61] H. K. van der Burgh, R. Schmidt, H.-J. Westeneng, M. A.\nde Reus, L. H. van den Berg, M. P. van den Heuvel, Deep\nlearning predictions of survival based on mri in amyotrophic\nlateral sclerosis, NeuroImage: Clinical 13 (2017) 361{369. [62] X. Li, X. Zhang, Z. Luo, Brain tumor segmentation via 3d fully\ndilated convolutional networks, in: Multimodal Brain Tumor\nSegmentation Benchmark, Brain-lesion Workshop, MICCAI,\nVol. 9, 2017, p. 2017. [63] M. M. Lopez, J. Ventura, Dilated convolutions for brain tumor\nsegmentation in mri scans, in: International MICCAI Brainle-\nsion Workshop, Springer, 2017, pp. 253{262. [64] L. Zhao, Automatic brain tumor segmentation with 3d decon-\nvolution network with dilated inception block, MICCAI BraTS\n(2017) 316{320. [65] M. Islam, V. Vibashan, V. J. M. Jose, N. Wijethilake,\nU. Utkarsh, H. Ren, Brain tumor segmentation and survival\nprediction using 3d attention unet, in: International MICCAI\nBrainlesion Workshop, Springer, 2019, pp. 262{272. [66] H. Wang, G. Wang, Z. Liu, S. Zhang, Global and local multi-\nscale feature fusion enhancement for brain tumor segmentation\nand pancreas segmentation, in: International MICCAI Brain-\nlesion Workshop, Springer, 2019, pp. 80{88. [67] C. Liu, W. Ding, L. Li, Z. Zhang, C. Pei, L. Huang, X. Zhuang,\nBrain tumor segmentation network using attention-based\nfusion and spatial relationship constraint, arXiv preprint\narXiv:2010.15647. [68] T. Zhou, S. Ruan, Y. Guo, S. Canu, A multi-modality fusion\nnetwork based on attention mechanism for brain tumor seg-\nmentation, in: 2020 IEEE 17th international symposium on\nbiomedical imaging (ISBI), IEEE, 2020, pp. 377{380. [69] S. Andermatt, S. Pezold, P. Cattin, Multi-dimensional gated\nrecurrent units for brain tumor segmentation, in: International\nMICCAI BraTS Challenge. Pre-Conference Proceedings, 2017,\npp. 15{19. [70] R. Br\u007f ugger, C. F. Baumgartner, E. Konukoglu, A partially re-\nversible u-net for memory-e\u000ecient volumetric image segmenta-\ntion, in: International conference on medical image computing\nand computer-assisted intervention, Springer, 2019, pp. 429{\n437. [71] C. Chen, X. Liu, M. Ding, J. Zheng, J. Li, 3d dilated multi-\n\fber network for real-time brain tumor segmentation in mri,\nin: International Conference on Medical Image Computing and\nComputer-Assisted Intervention, Springer, 2019, pp. 184{192. [72] X. Cheng, Z. Jiang, Q. Sun, J. Zhang, Memory-e\u000ecient cas-\ncade 3d u-net for brain tumor segmentation, in: International\nMICCAI Brainlesion Workshop, Springer, 2019, pp. 242{253. [73] M. Pendse, V. Thangarasa, V. Chiley, R. Holmdahl, J. Hes-\ntness, D. DeCoste, Memory e\u000ecient 3d u-net with reversible\nmobile inverted bottlenecks for brain tumor segmentation, in:\nInternational MICCAI Brainlesion Workshop, Springer, 2020,\npp. 388{397. [74] L. Zhao, K. Jia, Multiscale cnns for brain tumor segmentation\nand diagnosis, Computational and mathematical methods in\nmedicine 2016. [75] H. Shen, J. Zhang, W. Zheng, E\u000ecient symmetry-driven fully\nconvolutional network for multimodal brain tumor segmenta-\ntion, in: 2017 IEEE International Conference on Image Pro-\ncessing (ICIP), IEEE, 2017, pp. 3864{3868. [76] L. S. Castillo, L. A. Daza, L. C. Rivera, P. Arbel\u0013 aez, Volumet-\nric multimodality neural network for brain tumor segmenta-\ntion, in: 13th international conference on medical information\nprocessing and analysis, Vol. 10572, International Society for\nOptics and Photonics, 2017, p. 105720E.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 41, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.26787819253438117, "word_count": 509, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000040", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000042"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000042", "content": "[76] L. S. Castillo, L. A. Daza, L. C. Rivera, P. Arbel\u0013 aez, Volumet-\nric multimodality neural network for brain tumor segmenta-\ntion, in: 13th international conference on medical information\nprocessing and analysis, Vol. 10572, International Society for\nOptics and Photonics, 2017, p. 105720E. [77] A. Jungo, R. McKinley, R. Meier, U. Knecht, L. Vera, J. P\u0013 erez-\nBeteta, D. Molina-Garc\u0013 \u0010a, V. M. P\u0013 erez-Garc\u0013 \u0010a, R. Wiest,\nM. Reyes, Towards uncertainty-assisted brain tumor segmenta-\ntion and survival prediction, in: International MICCAI Brain-\nlesion Workshop, Springer, 2017, pp. 474{485. [78] M. Shaikh, G. Anand, G. Acharya, A. Amrutkar, V. Alex,\nG. Krishnamurthi, Brain tumor segmentation using dense\nfully convolutional neural network, in: International MICCAIbrainlesion workshop, Springer, 2017, pp. 309{319. [79] Z. Zhou, Z. He, Y. Jia, Afpnet: A 3d fully convolutional neural\nnetwork with atrous-convolution feature pyramid for brain tu-\nmor segmentation via mri images, Neurocomputing 402 (2020)\n235{244. [80] T. Zhou, S. Canu, P. Vera, S. Ruan, Latent correlation repre-\nsentation learning for brain tumor segmentation with missing\nmri modalities, IEEE Transactions on Image Processing 30\n(2021) 4263{4274. [81] P. Dvo\u0014 r\u0013 ak, B. Menze, Local structure prediction with convolu-\ntional neural networks for multimodal brain tumor segmenta-\ntion, in: International MICCAI workshop on medical computer\nvision, Springer, 2015, pp. 59{71. [82] V. Rao, M. S. Sarabi, A. Jaiswal, Brain tumor segmentation\nwith deep learning, MICCAI Multimodal Brain Tumor Seg-\nmentation Challenge (BraTS) 59. [83] K. Simonyan, A. Zisserman, Very deep convolutional net-\nworks for large-scale image recognition, arXiv preprint\narXiv:1409.1556. [84] A. Casamitjana, S. Puch, A. Aduriz, E. Sayrol, V. Vilaplana,\n3d convolutional networks for brain tumor segmentation, Pro-\nceedings of the MICCAI Challenge on Multimodal Brain Tu-\nmor Image Segmentation (BRATS) (2016) 65{68. [85] A. Jesson, T. Arbel, Brain tumor segmentation using a 3d fcn\nwith multi-scale loss, in: International MICCAI Brainlesion\nWorkshop, Springer, 2017, pp. 392{402. [86] P. D. Chang, Fully convolutional deep residual neural networks\nfor brain tumor segmentation, in: International workshop on\nBrainlesion: Glioma, multiple sclerosis, stroke and traumatic\nbrain injuries, Springer, 2016, pp. 108{118. [87] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for\nimage recognition, in: Proceedings of the IEEE conference on\ncomputer vision and pattern recognition, 2016, pp. 770{778. [88] M. Gha\u000bari, A. Sowmya, R. Oliver, Brain tumour segmenta-\ntion using cascaded 3d densely-connected u-net (2020). arXiv:\n2009.07563 . [89] Y. Wang, Y. Zhang, F. Hou, Y. Liu, J. Tian, C. Zhong,\nY. Zhang, Z. He, Modality-pairing learning for brain tumor\nsegmentation, arXiv preprint arXiv:2010.09277. [90] Z. Zhou, Z. He, M. Shi, J. Du, D. Chen, 3d dense connectivity\nnetwork with atrous convolutional feature pyramid for brain\ntumor segmentation in magnetic resonance imaging of human\nheads, Comput. Biol. Medicine 121 (2020) 103766. doi:10. 1016/j.compbiomed.2020.103766 . URL https://doi.org/10.1016/j.compbiomed.2020.103766\n[91] G. Huang, Z. Liu, L. Van Der Maaten, K. Q. Weinberger,\nDensely connected convolutional networks, in: Proceedings of\nthe IEEE conference on computer vision and pattern recogni-\ntion, 2017, pp. 4700{4708.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 42, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.2825557809330629, "word_count": 493, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000041", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000043"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000043", "content": "URL https://doi.org/10.1016/j.compbiomed.2020.103766\n[91] G. Huang, Z. Liu, L. Van Der Maaten, K. Q. Weinberger,\nDensely connected convolutional networks, in: Proceedings of\nthe IEEE conference on computer vision and pattern recogni-\ntion, 2017, pp. 4700{4708. [92] F. Yu, V. Koltun, T. Funkhouser, Dilated residual networks,\nin: Proceedings of the IEEE conference on computer vision\nand pattern recognition, 2017, pp. 472{480. [93] A. R. Choudhury, R. Vanguri, S. R. Jambawalikar, P. Kumar,\nSegmentation of brain tumors using deeplabv3+, in: Inter-\nnational MICCAI Brainlesion Workshop, Springer, 2018, pp. 154{167. [94] S. Andermatt, S. Pezold, P. Cattin, Multi-dimensional gated\nrecurrent units for the segmentation of biomedical 3d-data,\nin: Deep learning and data labeling for medical applications,\nSpringer, 2016, pp. 142{151. [95] A. N. Gomez, M. Ren, R. Urtasun, R. B. Grosse, The re-\nversible residual network: Backpropagation without storing ac-\ntivations, in: Proceedings of the 31st International Conference\non Neural Information Processing Systems, 2017, pp. 2211{\n2221. [96] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, L.-C. Chen,\nMobilenetv2: Inverted residuals and linear bottlenecks, in:\nProceedings of the IEEE conference on computer vision and\npattern recognition, 2018, pp. 4510{4520. [97] M. Tan, Q. Le, E\u000ecientnet: Rethinking model scaling for con-\nvolutional neural networks, in: International Conference on\n23", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 43, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.24705882352941175, "word_count": 204, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000042", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000044"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000044", "content": "--- Page 24 ---\nMachine Learning, PMLR, 2019, pp. 6105{6114. [98] N. Nuechterlein, S. Mehta, 3d-espnet with pyramidal re\fne-\nment for volumetric brain tumor image segmentation, in: In-\nternational MICCAI Brainlesion Workshop, Springer, 2018,\npp. 245{253. [99] G. Urban, M. Bendszus, F. Hamprecht, J. Kleesiek, Multi-\nmodal brain tumor segmentation using deep convolutional\nneural networks, MICCAI BraTS (brain tumor segmentation)\nchallenge. Proceedings, winning contribution (2014) 31{35. [100] M. Akil, R. Saouli, R. Kachouri, et al., Fully automatic brain\ntumor segmentation with deep learning-based selective atten-\ntion using overlapping patches and multi-class weighted cross-\nentropy, Medical image analysis 63 (2020) 101692. [101] K. Kamnitsas, C. Ledig, V. F. Newcombe, J. P. Simpson, A. D.\nKane, D. K. Menon, D. Rueckert, B. Glocker, E\u000ecient multi-\nscale 3d cnn with fully connected crf for accurate brain lesion\nsegmentation, Medical image analysis 36 (2017) 61{78. [102] H. Shen, R. Wang, J. Zhang, S. J. McKenna, Boundary-aware\nfully convolutional network for brain tumor segmentation, in:\nInternational Conference on Medical Image Computing and\nComputer-Assisted Intervention, Springer, 2017, pp. 433{441. [103] T. Brosch, L. Y. Tang, Y. Yoo, D. K. Li, A. Traboulsee,\nR. Tam, Deep 3d convolutional encoder networks with short-\ncuts for multiscale feature integration applied to multiple scle-\nrosis lesion segmentation, IEEE transactions on medical imag-\ning 35 (5) (2016) 1229{1239. [104] F. Isensee, P. Kickingereder, W. Wick, M. Bendszus, K. H.\nMaier-Hein, Brain tumor segmentation and radiomics survival\nprediction: Contribution to the brats 2017 challenge, in: Inter-\nnational MICCAI Brainlesion Workshop, Springer, 2017, pp. 287{297. [105] H. Dong, G. Yang, F. Liu, Y. Mo, Y. Guo, Automatic brain\ntumor detection and segmentation using u-net based fully con-\nvolutional networks, in: annual conference on medical image\nunderstanding and analysis, Springer, 2017, pp. 506{517. [106] F. Milletari, N. Navab, S.-A. Ahmadi, V-net: Fully convolu-\ntional neural networks for volumetric medical image segmen-\ntation, in: 3D Vision (3DV), 2016 Fourth International Con-\nference on, IEEE, 2016, pp. 565{571. [107] A. Beers, K. Chang, J. Brown, E. Sartor, C. Mammen,\nE. Gerstner, B. Rosen, J. Kalpathy-Cramer, Sequential 3d u-\nnets for biologically-informed brain tumor segmentation, arXiv\npreprint arXiv:1709.02967. [108] S. Chen, C. Ding, C. Zhou, Brain tumor segmentation with\nlabel distribution learning and multi-level feature representa-\ntion, 2017 International MICCAI BraTS Challenge. [109] S. Chen, C. Ding, M. Liu, Dual-force convolutional neural net-\nworks for accurate brain tumor segmentation, Pattern Recog-\nnition 88 (2019) 90{100. [110] K. Pawar, Z. Chen, N. J. Shah, G. Egan, Residual encoder and\nconvolutional decoder neural network for glioma segmentation,\nin: International MICCAI Brainlesion Workshop, Springer,\n2017, pp. 263{273. [111] W. Chen, B. Liu, S. Peng, J. Sun, X. Qiao, S3d-unet: sepa-\nrable 3d u-net for brain tumor segmentation, in: International\nMICCAI Brainlesion Workshop, Springer, 2018, pp. 358{368. [112] L. Fang, H. He, Three pathways u-net for brain tumor seg-\nmentation, in: Pre-conference proceedings of the 7th medical\nimage computing and computer-assisted interventions (MIC-\nCAI) BraTS Challenge, Vol. 2018, 2018, pp. 119{126. [113] R. Hua, Q. Huo, Y. Gao, Y.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 44, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.1601202404809619, "word_count": 499, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000043", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000045"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000045", "content": "119{126. [113] R. Hua, Q. Huo, Y. Gao, Y. Sun, F. Shi, Multimodal brain\ntumor segmentation using cascaded v-nets, in: International\nMICCAI Brainlesion Workshop, Springer, 2018, pp. 49{60. [114] X. Li, Fused u-net for brain tumor segmentation based on mul-\ntimodal mr images, International MICCAI Brain Tumor Seg-\nmentation (BraTS) challenge (2018) 290{297. [115] Y.-X. Zhao, Y.-M. Zhang, C.-L. Liu, Bag of tricks for 3d mri\nbrain tumor segmentation, in: International MICCAI Brainle-\nsion Workshop, Springer, 2019, pp. 210{220. [116] Y. Yuan, Automatic brain tumor segmentation with scale at-\ntention network, in: BrainLes@MICCAI, 2020. [117] T. Henry, A. Carre, M. Lerousseau, T. Estienne, C. Robert,\nN. Paragios, E. Deutsch, Brain tumor segmentation with\nself-ensembled, deeply-supervised 3d u-net neural net-\nworks: a brats 2020 challenge solution, arXiv preprint\narXiv:2011.01045. [118] W. Bae, S. Lee, Y. Lee, B. Park, M. Chung, K.-H. Jung, Re-\nsource optimized neural architecture search for 3d medical im-\nage segmentation, in: International Conference on Medical Im-\nage Computing and Computer-Assisted Intervention, Springer,\n2019, pp. 228{236. [119] S. Kim, I. Kim, S. Lim, W. Baek, C. Kim, H. Cho, B. Yoon,\nT. Kim, Scalable neural architecture search for 3d medical im-\nage segmentation, in: International Conference on Medical Im-\nage Computing and Computer-Assisted Intervention, Springer,\n2019, pp. 220{228. [120] Z. Zhou, M. M. R. Siddiquee, N. Tajbakhsh, J. Liang, Unet++:\nRedesigning skip connections to exploit multiscale features in\nimage segmentation, IEEE transactions on medical imaging\n39 (6) (2019) 1856{1867. [121] Z. Zhu, C. Liu, D. Yang, A. Yuille, D. Xu, V-nas: Neural\narchitecture search for volumetric medical image segmentation,\nin: 2019 International Conference on 3D Vision (3DV), IEEE,\n2019, pp. 240{248. [122] Q. Dong, S. Gong, X. Zhu, Imbalanced deep learning by minor-\nity class incremental recti\fcation, IEEE transactions on pat-\ntern analysis and machine intelligence 41 (6) (2018) 1367{1381. [123] J. M. Johnson, T. M. Khoshgoftaar, Survey on deep learning\nwith class imbalance, Journal of Big Data 6 (1) (2019) 1{54. [124] H. Jia, W. Cai, H. Huang, Y. Xia, H2nf-net for brain tumor\nsegmentation using multimodal mr imaging: 2nd place solu-\ntion to brats challenge 2020 segmentation task, in: BrainLes@\nMICCAI (2), 2020. [125] K. Sun, B. Xiao, D. Liu, J. Wang, Deep high-resolution rep-\nresentation learning for human pose estimation, in: CVPR,\n2019. [126] X. Li, G. Luo, K. Wang, Multi-step cascaded networks for\nbrain tumor segmentation, in: International MICCAI Brainle-\nsion Workshop, Springer, 2019, pp. 163{173. [127] M. H. Vu, T. Nyholm, T. L\u007f ofstedt, Tunet: End-to-end hierar-\nchical brain tumor segmentation using cascaded networks, in:\nInternational MICCAI Brainlesion Workshop, Springer, 2019,\npp. 174{186. [128] Z. Liu, D. Gu, Y. Zhang, X. Cao, Z. Xue, Automatic segmenta-\ntion of non-tumor tissues in glioma mr brain images using de-\nformable registration with partial convolutional networks, in:\nInternational MICCAI Brainlesion Workshop, Springer, 2020,\npp. 41{50. [129] M. D. Cirillo, D. Abramian, A. Eklund, Vox2vox: 3d-gan for\nbrain tumour segmentation, arXiv preprint arXiv:2003.13653. [130] H. Chen, Z. Qin, Y. Ding, L. Tian, Z. Qin, Brain tumor seg-\nmentation with deep convolutional symmetric neural network,\nNeurocomputing 392 (2020) 305{313.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 45, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.2171875, "word_count": 512, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000044", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000046"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000046", "content": "[129] M. D. Cirillo, D. Abramian, A. Eklund, Vox2vox: 3d-gan for\nbrain tumour segmentation, arXiv preprint arXiv:2003.13653. [130] H. Chen, Z. Qin, Y. Ding, L. Tian, Z. Qin, Brain tumor seg-\nmentation with deep convolutional symmetric neural network,\nNeurocomputing 392 (2020) 305{313. [131] K. Kamnitsas, E. Ferrante, S. Parisot, C. Ledig, A. V. Nori,\nA. Criminisi, D. Rueckert, B. Glocker, Deepmedic for brain tu-\nmor segmentation, in: International workshop on Brainlesion:\nGlioma, multiple sclerosis, stroke and traumatic brain injuries,\nSpringer, 2016, pp. 138{149. [132] P.-Y. Kao, T. Ngo, A. Zhang, J. W. Chen, B. Manjunath,\nBrain tumor segmentation and tractographic feature extrac-\ntion from structural mr images for overall survival prediction,\nin: International MICCAI Brainlesion Workshop, Springer,\n2018, pp. 128{141. [133] D. Lachinov, E. Shipunova, V. Turlapov, Knowledge distilla-\ntion for brain tumor segmentation, in: International MICCAI\nBrainlesion Workshop, Springer, 2019, pp. 324{332. [134] D. Lachinov, E. Vasiliev, V. Turlapov, Glioma segmentation\nwith cascaded unet, in: International MICCAI Brainlesion\nWorkshop, Springer, 2018, pp. 189{198. [135] X. Zhao, Y. Wu, G. Song, Z. Li, Y. Zhang, Y. Fan, 3d brain\ntumor segmentation through integrating multiple 2d fcnns, in:\nInternational MICCAI Brainlesion Workshop, Springer, 2017,\n24", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 46, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.4092783505154639, "word_count": 194, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000045", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000047"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000047", "content": "--- Page 25 ---\npp. 191{203. [136] V. Sundaresan, L. Gri\u000banti, M. Jenkinson, Brain tumour seg-\nmentation using a triplanar ensemble of u-nets on mr images,\nin: International MICCAI Brainlesion Workshop, Springer,\n2020, pp. 340{353. [137] L. Chen, P. Bentley, D. Rueckert, Fully automatic acute is-\nchemic lesion segmentation in dwi using convolutional neural\nnetworks, NeuroImage: Clinical 15 (2017) 633{643. [138] H. Noh, S. Hong, B. Han, Learning deconvolution network for\nsemantic segmentation, in: Proceedings of the IEEE interna-\ntional conference on computer vision, 2015, pp. 1520{1528. [139] Y. Hu, Y. Xia, 3d deep neural network-based brain tumor seg-\nmentation using multimodality magnetic resonance sequences,\nin: International MICCAI Brainlesion Workshop, Springer,\n2017, pp. 423{434. [140] C. A. Silva, A. Pinto, S. Pereira, A. Lopes, Multi-stage deep\nlayer aggregation for brain tumor segmentation, in: Inter-\nnational MICCAI Brainlesion Workshop, Springer, 2020, pp. 179{188. [141] C. Zhou, S. Chen, C. Ding, D. Tao, Learning contextual and\nattentive information for brain tumor segmentation, in: Inter-\nnational MICCAI brainlesion workshop, Springer, 2018, pp. 497{507. [142] H. Shen, R. Wang, J. Zhang, S. McKenna, Multi-task fully\nconvolutional network for brain tumour segmentation, in: An-\nnual Conference on Medical Image Understanding and Analy-\nsis, Springer, 2017, pp. 239{248. [143] H. T. Nguyen, T. T. Le, T. V. Nguyen, N. T. Nguyen, Enhanc-\ning mri brain tumor segmentation with an additional classi\f-\ncation network, arXiv preprint arXiv:2009.12111. [144] L. Weninger, Q. Liu, D. Merhof, Multi-task learning for brain\ntumor segmentation, in: International MICCAI brainlesion\nworkshop, Springer, 2019, pp. 327{337. [145] J. Iwasawa, Y. Hirano, Y. Sugawara, Label-e\u000ecient multi-\ntask segmentation using contrastive learning, arXiv preprint\narXiv:2009.11160. [146] R. Caruana, Multitask learning, Machine learning 28 (1)\n(1997) 41{75. [147] T. Evgeniou, M. Pontil, Regularized multi{task learning, in:\nProceedings of the tenth ACM SIGKDD international confer-\nence on Knowledge discovery and data mining, 2004, pp. 109{\n117. [148] O. Sener, V. Koltun, Multi-task learning as multi-objective\noptimization, in: Proceedings of the 32nd International Con-\nference on Neural Information Processing Systems, 2018, pp. 525{536. [149] Y. Zhang, Q. Yang, A survey on multi-task learning, IEEE\nTransactions on Knowledge and Data Engineering. [150] R. S. Randhawa, A. Modi, P. Jain, P. Warier, Improving\nboundary classi\fcation for brain tumor segmentation and lon-\ngitudinal disease progression, in: International Workshop on\nBrainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic\nBrain Injuries, Springer, 2016, pp. 65{74. [151] K. Pawar, Z. Chen, N. J. Shah, G. F. Egan, An ensemble\nof 2d convolutional neural network for 3d brain tumor seg-\nmentation, in: International MICCAI Brainlesion Workshop,\nSpringer, 2019, pp. 359{367. [152] K.-L. Tseng, Y.-L. Lin, W. Hsu, C.-Y. Huang, Joint sequence\nlearning and cross-modality convolution for 3d biomedical seg-\nmentation, in: Proceedings of the IEEE conference on Com-\nputer Vision and Pattern Recognition, 2017, pp. 6393{6400. [153] M. Cat\u0012 a, A. Casamitjana D\u0013 \u0010az, I. Sanchez Muriana, M. Com-\nbalia, V. Vilaplana Besler, Masked v-net: an approach to brain\ntumor segmentation, in: 2017 International MICCAI BraTS\nChallenge. Pre-conference proceedings, 2017, pp. 42{49.", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 47, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.22048192771084335, "word_count": 498, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000046", "next_chunk_id": "96b89ace-37d7-42ed-77fd-347700000048"}}, {"id": "96b89ace-37d7-42ed-77fd-347700000048", "content": "Pre-conference proceedings, 2017, pp. 42{49. [154] D. Zhang, G. Huang, Q. Zhang, J. Han, J. Han, Y. Wang,\nY. Yu, Exploring task structure for brain tumor segmentation\nfrom multi-modality mr images, IEEE Transactions on Image\nProcessing 29 (2020) 9032{9043. [155] Y. Li, L. Shen, Deep learning based multimodal brain tumor\ndiagnosis, in: International MICCAI Brainlesion Workshop,Springer, 2017, pp. 149{158. [156] B. Yu, L. Zhou, L. Wang, J. Fripp, P. Bourgeat, 3d cgan based\ncross-modality mr image synthesis for brain tumor segmenta-\ntion, in: 2018 IEEE 15th International Symposium on Biomed-\nical Imaging (ISBI 2018), IEEE, 2018, pp. 626{630. [157] T. Zhou, S. Canu, P. Vera, S. Ruan, Brain tumor segmenta-\ntion with missing modalities via latent multi-source correlation\nrepresentation, in: International Conference on Medical Im-\nage Computing and Computer-Assisted Intervention, Springer,\n2020, pp. 533{541. [158] B. Yu, L. Zhou, L. Wang, W. Yang, M. Yang, P. Bourgeat,\nJ. Fripp, Sa-lut-nets: Learning sample-adaptive intensity\nlookup tables for brain tumor segmentation, IEEE Transac-\ntions on Medical Imaging 40 (5) (2021) 1417{1427. 25", "metadata": {"source": "deep_learning_based_brain_tumor_segmentation_a_survey.pdf", "file_type": "pdf", "num_pages": 25, "author": "Zhihua Liu; Lei Tong; Zheheng Jiang; Long Chen; Feixiang Zhou; Qianni Zhang; Xiangrong Zhang; Yaochu Jin; Huiyu Zhou; ", "creationdate": "D:20211118011737Z", "creator": "LaTeX with hyperref", "moddate": "D:20211118011737Z", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2", "producer": "pdfTeX-1.40.21", "title": "Deep Learning Based Brain Tumor Segmentation: A Survey", "trapped": "/False", "medical_entities": {"diseases": ["alzheimer's", "cancer", "stroke"], "procedures": ["surgery", "mri"], "anatomy": ["pancreas", "liver", "brain", "nerve"]}, "document_type": "research_paper", "processing_timestamp": "2025-03-22T23:48:15.658833", "chunk_number": 48, "total_chunks": 49, "section": "paragraph", "hierarchy_level": "sentences", "importance_score": 0.4264705882352941, "word_count": 170, "chunking_strategy": "hybrid", "previous_chunk_id": "96b89ace-37d7-42ed-77fd-347700000047"}}]